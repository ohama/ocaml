[
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/intro/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "ocamllex is a tool for generating scanners: programs which recognized lexical patterns in text. ocamllex reads the given input files, for a description of a scanner to generate. The description is in the form of pairs of regular expressions and Ocaml code, called rules. ocamllex generates as output a Ocaml source file which defines lexical analyzer functions. This file is compiled and linked to produce an executable. When the executable is run, it analyzes its input for occurrences of the regular expressions. Whenever it finds one, it executes the corresponding Ocaml code.\nIf you execute the following command with the input file named lexer.mll\nocamllex lexer.mll you will get Caml code for a lexical analyzer in file lexer.ml\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/usagetips/keywordtable/",
	"title": "Keyword table",
	"tags": [],
	"description": "",
	"content": "The number of status transitions generated by ocamllex are limited to at most 32767. If you use too many transitions, for example, too many keywords, ocamllex generates the following error message:\ncamllex: transition table overflow, automaton is too big  It tells that your lexer definition is too complex. To make the generated automata small, you have to encode using keyword table:\n{ let keyword_table = Hashtbl.create 72 let _ = List.iter (fun (kwd, tok) -\u0026gt; Hashtbl.add keyword_table kwd tok) [ (\u0026quot;keyword1\u0026quot;, KEYWORD1); (\u0026quot;keyword2\u0026quot;, KEYWORD2); ... ] } rule token = parse | ... | ['A'-'Z' 'a'-'z'] ['A'-'Z' 'a'-'z' '0'-'9' '_']* as id { try Hashtbl.find keyword_table id with Not_found -\u0026gt; IDENT id } | ...  For a complete example, see Toy Language program.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/license/licenseinflex/",
	"title": "License in flex manual",
	"tags": [],
	"description": "",
	"content": "Copyright \u0026copy; 1990 The Regents of the University of California. All rights reserved.\nThis code is derived from software contributed to Berkeley by Vern Paxson.\nThe United States Government has rights in this work pursuant to contract no. DE-AC03-76SF00098 between the United States Department of Energy and the University of California.\nRedistribution and use in source and binary forms with or without modification are permitted provided that: (1) source distributions retain this entire copyright notice and comment, and (2) distributions including binaries display the following acknowledgement: \u0026ldquo;This product includes software developed by the University of California, Berkeley and its contributors\u0026rdquo; in the documentation or other materials provided with the distribution and in all advertising materials mentioning features or use of this software. Neither the name of the University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED \u0026ldquo;AS IS\u0026rdquo; AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/",
	"title": "Ocamllex tutorial",
	"tags": [],
	"description": "This is a tutorial on how to use ocamllex.",
	"content": " This is a tutorial on how to use ocamllex which is distributed with Ocaml language.\nAbout this document Lots of part of this document are borrowed from the flex manual.\nAll license term in this document is NOT related with ocamlyacc; it is ONLY for this document.\nPlease mail all comments and suggestions to me.\nThe companion tutorial for ocamlyacc is available at ocamlyacc tutorial.\nYou can find the ocamllex tutorial pdf file for printing.\nThe source of the examples used in this document can be found ocamllex examples.\n  Related files   ocamllex-tutorial.pdf  (133 ko)    "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/actions/position/",
	"title": "Position",
	"tags": [],
	"description": "",
	"content": " Since Ocaml 3.08\n The position information on scanning the input text is recorded in the lexbuf which has a field lex_curr_p of the type position:\n type position = { pos_fname : string;\t(* file name *) pos_lnum : int;\t(* line number *) pos_bol : int;\t(* the offset of the beginning of the line *) pos_cnum : int;\t(* the offset of the position *) }  The value of pos_bol field is the number of characters between the beginning of the file and the beginning of the line while the value of pos_cnum field is the number of characters between the beginning of the file and the position.\nThe lexing engine manages only the pos_cnum field of lexbuf.lex_curr_p with the number of characters read from the start of lexbuf. So you are reponsible for the other fields to be accurate. Typically, whenever the lexer meets a newline character, the action contains a call to the following function:\n let incr_linenum lexbuf = let pos = lexbuf.Lexing.lex_curr_p in lexbuf.Lexing.lex_curr_p \u0026amp;lt;- { pos with Lexing.pos_lnum = pos.Lexing.pos_lnum + 1; Lexing.pos_bol = pos.Lexing.pos_cnum; } ;;  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/examples/translate/",
	"title": "Translate",
	"tags": [],
	"description": "",
	"content": "This example translates the text \u0026ldquo;current_directory\u0026rdquo; to the current directory.\n{ } rule translate = parse | \u0026quot;current_directory\u0026quot;\t{ print_string (Sys.getcwd ()) } | _ as c\t{ print_char c } | eof\t{ exit 0 } { let main () = let lexbuf = Lexing.from_channel stdin in while true do translate lexbuf done let _ = Printexc.print main () }  "
},
{
	"uri": "https://ohama.github.io/ocaml/",
	"title": "Tutorials",
	"tags": [],
	"description": "",
	"content": "  Ocamllex tutorial  This is a tutorial on how to use ocamllex.\n Ocamlyacc tutorial  This is a tutorial on how to use ocamlyacc.\n lablgtk2 tutorial  lablgtk2 tutorial\n lablgtk2 treeview tutorial  lablgtk2 treeview tutorial\n   \n "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/license/copyright/",
	"title": "Copyright and permission",
	"tags": [],
	"description": "",
	"content": " Ocamllex Adaptation Copyright and Permissions Notice Copyright \u0026copy; 2004 SooHyoung Oh.\nPermission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies.\nPermission is granted to copy and distribute modified versions of this document under the conditions for verbatim copying, provided that this copyright notice is included exactly as in the original, and that the entire resulting derived work is distributed under the terms of a permission notice identical to this one.\nPermission is granted to copy and distribute translations of this document into another language, under the above conditions for modified versions.\nIf you are intending to incorporate this document into a published work, please contact the maintainer, and we will make an effort to ensure that you have the most up to date information available.\nThere is no guarantee that this document lives up to its intended purpose. This is simply provided as a free resource. As such, the authors and maintainers of the information provided within can not make any guarantee that the information is even accurate.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/usagetips/nestedcomments/",
	"title": "Nested comments",
	"tags": [],
	"description": "",
	"content": "Some language such as Ocaml support nested comment. It can be implemented like this:\n{ } rule token = parse | \u0026quot;(*\u0026quot;\t{ print_endline \u0026quot;comments start\u0026quot;; comments 0 lexbuf } | [' ' '\\t' '\\n']\t{ token lexbuf } | ['a'-'z']+ as word { Printf.printf \u0026quot;word: %s\\n\u0026quot; word; token lexbuf } | _ as c\t{ Printf.printf \u0026quot;char %c\\n\u0026quot; c; token lexbuf } | eof\t{ raise End_of_file } and comments level = parse | \u0026quot;*)\u0026quot;\t{ Printf.printf \u0026quot;comments (%d) end\\n\u0026quot; level; if level = 0 then token lexbuf else comments (level-1) lexbuf } | \u0026quot;(*\u0026quot;\t{ Printf.printf \u0026quot;comments (%d) start\\n\u0026quot; (level+1); comments (level+1) lexbuf } | _\t{ comments level lexbuf } | eof\t{ print_endline \u0026quot;comments are not closed\u0026quot;; raise End_of_file }  When the scanner function meets comments start token \u0026ldquo;(\u0026rdquo; in evaluating token rule, it enters comments rule with level of 0. token rule is invoked again when all comments are closed. Comments nesting level is increased whenever there is comment start token \u0026ldquo;(\u0026rdquo; in the input text.\nIf the scanner function meets end of comments token \u0026ldquo;*)\u0026ldquo;, it tests the comments nesting level. When the nesting level is not zero, it decrements the level by one and continues to scan comments. It returns to token rule when all the comments are closed i.e., the nesting level is zero.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/",
	"title": "Ocamlyacc tutorial",
	"tags": [],
	"description": "This is a tutorial on how to use ocamlyacc.",
	"content": " This is a tutorial on how to use ocamlyacc which is distributed with Ocaml language.\nAbout this document Lots of part of this document are borrowed from the bison manual.\nAll license term in this document is NOT related with ocamlyacc; it is ONLY for this document.\nPlease mail all comments and suggestions to me.\nThe companion tutorial for ocamllex is available at ocamllex tutorial.\nYou can find the ocamlyacc tutorial pdf file for printing.\nThe source of the examples used in this document can be found ocamlyacc examples directory.\n  Related files   ocamlyacc-tutorial.pdf  (267 ko)    "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/simpleexample/",
	"title": "Some simple examples",
	"tags": [],
	"description": "",
	"content": "First some simple examples to get the flavor of how one uses ocamllex. The following ocamllex input specifies a scanner which whenever it encounters the string \u0026ldquo;current_directory\u0026rdquo; will replace it with the current directory:\n{ } rule translate = parse | \u0026quot;current_directory\u0026quot;\t{ print_string (Sys.getcwd ()); translate lexbuf } | _ as c\t{ print_char c; translate lexbuf } | eof\t{ exit 0 }  In the first rule, \u0026ldquo;current_directory\u0026rdquo; is the pattern and the expression between braces is the action. By this rule, when the scanner matches the string \u0026ldquo;current_directory\u0026rdquo;, it executes the corresponding action which prints the current directory name and call the scanner again. Recursive calling itself is necessary to do the other job.\nAny text not matched by a ocamllex scanner generates exception Failure \u0026ldquo;lexing: empty token\u0026rdquo;, so you have to supply the last two rules. The second rule copies any character to its output which is not matched by the first rule, and it calls itself again. By the third rule, the program exits when it meets end of file. So the net effect of this scanner is to copy its input file to its output with each occurrence of \u0026ldquo;current_directory\u0026rdquo; expanded. The \u0026ldquo;{ }\u0026rdquo; in the first line delimits the header section from the rest.\nHere\u0026rsquo;s another simple example:\n{ let num_lines = ref 0 let num_chars = ref 0 } rule count = parse | '\\n' { incr num_lines; incr num_chars; count lexbuf } | _ { incr num_chars; count lexbuf } | eof { () } { let main () = let lexbuf = Lexing.from_channel stdin in count lexbuf; Printf.printf \u0026quot;# of lines = %d, # of chars = %d\\n\u0026quot; !num_lines !num_chars let _ = Printexc.print main () }  This scanner counts the number of characters and the number of lines in its input (it produces no output other than the final report on the counts). The first header section declares two globals, \u0026ldquo;num_lines\u0026rdquo; and \u0026ldquo;num_chars\u0026rdquo;, which are accessible both inside scanner function count and in the trailer section which is the last part enclosed by braces. There are three rules, one which matches a newline (\u0026rdquo;\\n\u0026rdquo;) and increments both the line count and the character count, and one which matches any character other than a newline (indicated by the \u0026ldquo;_\u0026rdquo; regular expression). At the end of file, the scanner function count returns unit.\nA somewhat more complicated example:\n(* scanner for a toy language *) { open Printf } let digit = ['0'-'9'] let id = ['a'-'z'] ['a'-'z' '0'-'9']* rule toy_lang = parse | digit+ as inum { printf \u0026quot;integer: %s (%d)\\n\u0026quot; inum (int_of_string inum); toy_lang lexbuf } | digit+ '.' digit* as fnum { printf \u0026quot;float: %s (%f)\\n\u0026quot; fnum (float_of_string fnum); toy_lang lexbuf } | \u0026quot;if\u0026quot; | \u0026quot;then\u0026quot; | \u0026quot;begin\u0026quot; | \u0026quot;end\u0026quot; | \u0026quot;let\u0026quot; | \u0026quot;in\u0026quot; | \u0026quot;function\u0026quot; as word { printf \u0026quot;keyword: %s\\n\u0026quot; word; toy_lang lexbuf } | id as text { printf \u0026quot;identifier: %s\\n\u0026quot; text; toy_lang lexbuf } | '+' | '-' | '*' | '/' as op { printf \u0026quot;operator: %c\\n\u0026quot; op; toy_lang lexbuf } | '{' [^ '\\n']* '}'\t{ toy_lang lexbuf }\t(* eat up one-line comments *) | [' ' '\\t' '\\n']\t{ toy_lang lexbuf }\t(* eat up whitespace *) | _ as c { printf \u0026quot;Unrecognized character: %c\\n\u0026quot; c; toy_lang lexbuf } | eof\t{ } { let main () = let cin = if Array.length Sys.argv \u0026gt; 1 then open_in Sys.argv.(1) else stdin in let lexbuf = Lexing.from_channel cin in toy_lang lexbuf let _ = Printexc.print main () }  This is the beginnings of a simple scanner for a language. It identifies different types of tokens and reports on what it has seen.\nThe details of this example will be explained in the following sections.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/examples/wordcount/",
	"title": "Word count",
	"tags": [],
	"description": "",
	"content": "This example shows the number of lines, words and characters of the given file if the filename is given, or of the standard input if no command arguments are given.\n{ } rule count lines words chars = parse | '\\n'\t{ count (lines+1) words (chars+1) lexbuf } | [^ ' ' '\\t' '\\n']+ as word { count lines (words+1) (chars+ String.length word) lexbuf } | _\t{ count lines words (chars+1) lexbuf } | eof\t{ (lines, words, chars) } { let main () = let cin = if Array.length Sys.argv \u0026gt; 1 then open_in Sys.argv.(1) else stdin in let lexbuf = Lexing.from_channel cin in let (lines, words, chars) = count 0 0 0 lexbuf in Printf.printf \u0026quot;%d lines, %d words, %d chars\\n\u0026quot; lines words chars let _ = Printexc.print main () }  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/formatofinputfile/",
	"title": "Format of the input file",
	"tags": [],
	"description": "",
	"content": "The ocamllex input file consists of four sections; header, definitions, rules and trailer section:\n(* header section *) { \u0026lt;header\u0026gt; } (* definitions section *) let \u0026lt;ident\u0026gt; = \u0026lt;regexp\u0026gt; let ...\t(* rules section *) rule \u0026lt;entrypoint_1\u0026gt; [arg1... argn] = parse | \u0026lt;pattern\u0026gt; { \u0026lt;action\u0026gt; } | ... | \u0026lt;pattern\u0026gt; { \u0026lt;action\u0026gt; } and \u0026lt;entrypoint_2\u0026gt; [arg1... argn] = parse ... and ... (* trailer section *) { \u0026lt;trailer\u0026gt; }  Comments are delimited by (* and *), as in Caml.\nThe header and rules sections are necessary while definitions and trailer sections are optional.\nThe header and trailer sections are enclosed in curly braces and they contain arbitrary Caml code. At the beginning of the output file, the header text is copied as is while the trailer text is copied at the end of the output file. For example, you can code open directives and some auxiliary funtions in the header section.\nThe definitions section contains declarations of simple ident definitions to simplify the scanner specification. Ident definitions have the form:\nlet \u0026lt;ident\u0026gt; = \u0026lt;regexp\u0026gt; let ...\t The \u0026ldquo;ident\u0026rdquo; must be valid identifiers for Caml values (starting with a lowercase letter). For example,\nlet _digit_ = ['0'-'9'] let _id_ = ['a'-'z']['a'-'z' '0'-'9']*  defines \u0026ldquo;digit\u0026rdquo; to be a regular expression which matches a single digit, and \u0026ldquo;id\u0026rdquo; to be a regular expression which matches a letter followed by zero-or-more letters-or-digits. A subsequent reference to\ndigit+ \u0026quot;.\u0026quot; digit*  is identical to\n['0'-'9']+ \u0026quot;.\u0026quot; ['0'-'9']*  and matches one-or-more digits followed by a \u0026lsquo;.\u0026rsquo; followed by zero-or-more digits.\nThe rules section of the ocamllex input contains a series of entrypoints of the form:\nrule entrypoint [arg1... argn] = parse | \u0026lt;pattern\u0026gt; { \u0026lt;action\u0026gt; } | ... | \u0026lt;pattern\u0026gt; { \u0026lt;action\u0026gt; } and ...  The first \u0026ldquo;|\u0026rdquo; (bar) after parse is optional.\nEach entrypoint consists of a series of pattern-action:\n | \u0026lt;pattern\u0026gt; { \u0026lt;action\u0026gt; }  where the action must be enclosed in curly braces.\nSee below for a further description of patterns and actions.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/examples/toylanguage/",
	"title": "Toy language",
	"tags": [],
	"description": "",
	"content": "In this example, the scanner function toy_lang returns a value of token type, but the main function does nothing with it.\n{ open Printf let create_hashtable size init = let tbl = Hashtbl.create size in List.iter (fun (key, data) -\u0026gt; Hashtbl.add tbl key data) init; tbl type token = | IF | THEN | ELSE | BEGIN | END | FUNCTION | ID of string | OP of char | INT of int | FLOAT of float | CHAR of char let keyword_table = create_hashtable 8 [ (\u0026quot;if\u0026quot;, IF); (\u0026quot;then\u0026quot;, THEN); (\u0026quot;else\u0026quot;, ELSE); (\u0026quot;begin\u0026quot;, BEGIN); (\u0026quot;end\u0026quot;, END); (\u0026quot;function\u0026quot;, FUNCTION) ] } let digit = ['0'-'9'] let id = ['a'-'z' 'A'-'Z']['a'-'z' '0'-'9']* rule toy_lang = parse | digit+ as inum { let num = int_of_string inum in printf \u0026quot;integer: %s (%d)\\n\u0026quot; inum num; INT num } | digit+ '.' digit* as fnum { let num = float_of_string fnum in printf \u0026quot;float: %s (%f)\\n\u0026quot; fnum num; FLOAT num } | id as word { try let token = Hashtbl.find keyword_table word in printf \u0026quot;keyword: %s\\n\u0026quot; word; token with Not_found -\u0026gt; printf \u0026quot;identifier: %s\\n\u0026quot; word; ID word } | '+' | '-' | '*' | '/' as op { printf \u0026quot;operator: %c\\n\u0026quot; op; OP op } | '{' [^ '\\n']* '}'\t(* eat up one-line comments *) | [' ' '\\t' '\\n']\t(* eat up whitespace *) { toy_lang lexbuf } | _ as c { printf \u0026quot;Unrecognized character: %c\\n\u0026quot; c; CHAR c } | eof { raise End_of_file } { let rec parse lexbuf = let token = toy_lang lexbuf in (* do nothing in this example *) parse lexbuf let main () = let cin = if Array.length Sys.argv \u0026gt; 1 then open_in Sys.argv.(1) else stdin in let lexbuf = Lexing.from_channel cin in try parse lexbuf with End_of_file -\u0026gt; () let _ = Printexc.print main () }  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/patterns/",
	"title": "Patterns",
	"tags": [],
	"description": "",
	"content": "The patterns in the input are written using regular expressions in the style of lex, with a more Caml-like syntax. These are:\n \u0026lsquo;c\u0026rsquo;: match the character \u0026lsquo;c\u0026rsquo;. The character constant is the same syntax as Objective Caml character. _: (underscore) match any character. eof: match an end-of-file . \u0026ldquo;foo\u0026rdquo;: the literal string \u0026ldquo;foo\u0026rdquo;. The syntax is the same syntax as Objective Caml string constants. [\u0026lsquo;x\u0026rsquo; \u0026lsquo;y\u0026rsquo; \u0026lsquo;z\u0026rsquo;]: character set; in this case, the pattern matches either an \u0026lsquo;x\u0026rsquo;, a \u0026lsquo;y\u0026rsquo;, or a \u0026lsquo;z\u0026rsquo; . [\u0026lsquo;a\u0026rsquo; \u0026lsquo;b\u0026rsquo; \u0026lsquo;j\u0026rsquo;-\u0026lsquo;o\u0026rsquo; \u0026lsquo;Z\u0026rsquo;]: character set with a range in it; ranges of characters \u0026lsquo;c1\u0026rsquo; - \u0026lsquo;c2\u0026rsquo; (all characters between c1 and c2, inclusive); in this case, the pattern matches an \u0026lsquo;a\u0026rsquo;, a \u0026lsquo;b\u0026rsquo;, any letter from \u0026lsquo;j\u0026rsquo; through \u0026lsquo;o\u0026rsquo;, or a \u0026lsquo;Z\u0026rsquo;. [^ \u0026lsquo;A\u0026rsquo;-\u0026lsquo;Z\u0026rsquo;]: a negated character set, i.e., any character but those in the class. In this case, any character EXCEPT an uppercase letter. [^ \u0026lsquo;A\u0026rsquo;-\u0026lsquo;Z\u0026rsquo; \u0026lsquo;\\n\u0026rsquo;]: any character EXCEPT an uppercase letter or a newline r*: zero or more r\u0026rsquo;s, where r is any regular expression r+: one or more r\u0026rsquo;s, where r is any regular expression r?: zero or one r\u0026rsquo;s, where r is any regular expression (that is, \u0026ldquo;an optional r\u0026rdquo;) ident: the expansion of the \u0026ldquo;ident\u0026rdquo; defined by an earlier let ident = regexp definition. (r): match an r; parentheses are used to override precedence (see below) rs: the regular expression r followed by the regular expression s; called \u0026ldquo;concatenation\u0026rdquo; r|s: either an r or an s r#s: match the difference of the two specified character sets. r as ident: bind the string matched by r to identifier ident  The regular expressions listed above are grouped according to precedence, from highest precedence at the top to lowest at the bottom; \u0026lsquo;*\u0026rsquo; and \u0026lsquo;+\u0026rsquo; have highest precedence, followed by \u0026lsquo;?\u0026rsquo;, \u0026lsquo;concatenation\u0026rsquo;, \u0026lsquo;|\u0026rsquo;, and then \u0026lsquo;as\u0026rsquo;. For example,\n\u0026quot;foo\u0026quot; | \u0026quot;bar\u0026quot;*  is the same as\n(\u0026quot;foo\u0026quot;)|(\u0026quot;bar\u0026quot;*)  since the \u0026lsquo;*\u0026rsquo; operator has higher precedence than than alternation (\u0026lsquo;|\u0026rsquo;). This pattern therefore matches either the string \u0026ldquo;foo\u0026rdquo; or zero-or-more of the string \u0026ldquo;bar\u0026rdquo;.\nTo match zero-or-more \u0026ldquo;foo\u0026rdquo;\u0026rsquo;s-or-\u0026ldquo;bar\u0026rdquo;\u0026rsquo;s:\n(\u0026quot;foo\u0026quot;|\u0026quot;bar\u0026quot;)*  A negated character set such as the example \u0026ldquo;[^ \u0026lsquo;A\u0026rsquo;-\u0026lsquo;Z\u0026rsquo;]\u0026rdquo; above will match a newline unless \u0026ldquo;\\n\u0026rdquo; (or an equivalent escape sequence) is one of the characters explicitly present in the negated character set (e.g., \u0026ldquo;[^ \u0026lsquo;A\u0026rsquo;-\u0026lsquo;Z\u0026rsquo; \u0026lsquo;\\n\u0026rsquo;]\u0026ldquo;). This is unlike how many other regular expression tools treat negated character set, but unfortunately the inconsistency is historically entrenched. Matching newlines means that a pattern like [^\u0026ldquo;]* can match the entire input unless there\u0026rsquo;s another quote in the input.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/howmatched/",
	"title": "How the input is matched",
	"tags": [],
	"description": "",
	"content": "When the generated scanner is run, it analyzes its input looking for strings which match any of its patterns. If it finds more than one match, it takes the one matching the most text (the \u0026ldquo;longest match\u0026rdquo; principle). If it finds two or more matches of the same length, the rule listed first in the ocamllex input file is chosen (the \u0026ldquo;first match\u0026rdquo; principle).\nOnce the match is determined, the text corresponding to the match (called the token) is made available in the form of a string. The action corresponding to the matched pattern is then executed (a more detailed description of actions follows), and then the remaining input is scanned for another match.\nIf no match is found, the scanner raises the Failure \u0026ldquo;lexing: empty token\u0026rdquo; exception.\nNow, let\u0026rsquo;s see the examples which shows how the patterns are applied.\nrule token = parse | \u0026quot;ding\u0026quot;\t{ print_endline \u0026quot;Ding\u0026quot; }\t(* \u0026quot;ding\u0026quot; pattern *) | ['a'-'z']+ as word\t(* \u0026quot;word\u0026quot; pattern *) { print_endline (\u0026quot;Word: \u0026quot; ^ word) } ...  When \u0026ldquo;ding\u0026rdquo; is given as an input, the ding and word pattern can be matched. ding pattern is selected because it comes before word pattern. So if you code like this:\nrule token = parse | ['a'-'z']+ as word\t(* \u0026quot;word\u0026quot; pattern *) { print_endline (\u0026quot;Word: \u0026quot; ^ word) } | \u0026quot;ding\u0026quot;\t{ print_endline \u0026quot;Ding\u0026quot; }\t(* \u0026quot;ding\u0026quot; pattern *) | ...  ding pattern will be useless.\nIn the following example, there are three patterns: ding, dong and dingdong.\nrule token = parse | \u0026quot;ding\u0026quot;\t{ print_endline \u0026quot;Ding\u0026quot; }\t(* \u0026quot;ding\u0026quot; pattern *) | \u0026quot;dong\u0026quot;\t{ print_endline \u0026quot;Dong\u0026quot; }\t(* \u0026quot;dong\u0026quot; pattern *) | \u0026quot;dingdong\u0026quot;\t{ print_endline \u0026quot;Ding-Dong\u0026quot; }\t(* \u0026quot;dingdong\u0026quot; pattern *) ...  When \u0026ldquo;dingdong\u0026rdquo; is given as an input, there are two choices: ding + dong pattern or dingdong pattern. But by the \u0026ldquo;longest match\u0026rdquo; principle, dingdong pattern will be selected.\nThough the \u0026ldquo;shortest match\u0026rdquo; principle is not used so frequently, ocamllex supports it. If you want to select the shortest prefix of the input, use shortest keyword instead of the parse keyword. The \u0026ldquo;first match\u0026rdquo; principle holds still with the \u0026ldquo;shortest match\u0026rdquo; principle.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/actions/",
	"title": "Actions",
	"tags": [],
	"description": "",
	"content": "Each pattern in a rule has a corresponding action, which can be any arbitrary Ocaml expression. For example, here is the specification for a program which deletes all occurrences of \u0026ldquo;zap me\u0026rdquo; from its input:\n{} rule token = parse | \u0026quot;zap me\u0026quot;\t{ token lexbuf }\t(* ignore this token: no processing and continue *) | _ as c\t{ print_char c; token lexbuf }  Here is a program which compresses multiple blanks and tabs down to a single blank, and throws away whitespace found at the end of a line:\n{} rule token = parse | [' ' '\\t']+\t{ print_char ' '; token lexbuf } | [' ' '\\t']+ '\\n'\t{ token lexbuf } (* ignore this token *)  Actions can include arbitrary Ocaml code which returns a value. Each time the lexical analyzer function is called it continues processing tokens from where it last left off until it either reaches the end of the file.\nActions are evaluated after the lexbuf is bound to the current lexer buffer and the identifer following the keyword as to the matched string. The usage of lexbuf is provided by the Lexing standard library module;\n Lexing.lexeme lexbuf: Return the matched string. Lexing.lexeme_char lexbuf n: Return the _n_th character in the matched string. The index number of the first character starts from 0.\n Lexing.lexeme_start lexbuf\n Lexing.lexeme_end lexbuf: Return the absolute position in the input text of the beginning/end of the matched string. The position of the first character is 0.\n Lexing.lexeme_start_p lexbuf\n Lexing.lexeme_end_p lexbuf: (Since Ocaml 3.08) Return the position of type _position (See Position).\n entrypoint [exp1\u0026hellip; expn] lexbuf: Call the other lexer on the given entry point. Notice that lexbuf is the last argument.\n  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/generatedscanner/",
	"title": "The generted scanner",
	"tags": [],
	"description": "",
	"content": "The output of ocamllex is the file lex.ml when it is invoked as ocamllex lex.mll. The generated file contains the scanning functions, a number of tables used by it for matching tokens, and a number of auxiliary routines. The scanning functions are declared as followings:\nlet \u0026lt;entrypoint\u0026gt; [arg1... argn] lexbuf = ... and ...  where the fuction entrypoint has n + 1 arguments. n arguments come from the definition of the rules secton. And the resulting scanning function has one more argument named lexbuf of Lexing.lexbuf type as the last one.\nWhenever entrypoint is called, it scans tokens from the lexbuf argument. When it finds a match in patterns, it executes the corresponding action and returns. If you want to continue the lexical analyze after evaluating of the action, you must call the scanning function recursively.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/startcondition/",
	"title": "Start conditions",
	"tags": [],
	"description": "",
	"content": "ocamllex provides a mechanism for conditionally activating rules. When you want do activate the other rule, just call the other entrypoint function. For example, the following has two rules, one for finding tokens and one for skipping comments.\n{} rule token = parse | [' ' '\\t' '\\n']+ (* skip spaces *) { token lexbuf } | \u0026quot;(*\u0026quot; (* activate \u0026quot;comment\u0026quot; rule *) { comment lexbuf } ... and comment = parse | \u0026quot;*)\u0026quot; (* go to the \u0026quot;token\u0026quot; rule *) { token lexbuf } | _ (* skip comments *) { comment lexbuf } ...  When the generated scanner meets comment start token \u0026ldquo;(\u0026rdquo; at the token rule, it activates the other rule comment. When it meets the end of comment token \u0026ldquo;)\u0026rdquo; at the comment rule. it returns to the scanning token rule.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/interfacewithocamlyacc/",
	"title": "Interfacing with ocamlyacc",
	"tags": [],
	"description": "",
	"content": "One of the main uses of ocamllex is as a companion to the ocamlyacc parser-generator. ocamlyacc parsers call one of the scanning functions to find the next input token. The routine is supposed to return the type of the next token with an associated value. To use ocamllex with ocamlyacc, scanner functions should use parser module to refer token types, which are defined in `%tokens\u0026rsquo; attributes appearing in the ocamlyacc input. For example, if input filename of ocamlyacc is parse.mly and one of the tokens is \u0026ldquo;NUMBER\u0026rdquo;, part of the scanner might look like:\n{ open Parse } rule token = parse ... | ['0'-'9']+ as num { NUMBER (int_of_string num) } ...  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/license/bisonlicense/",
	"title": "Bison license",
	"tags": [],
	"description": "Bison License",
	"content": " The bison manual requires \u0026ldquo;GNU General Public License\u0026rdquo; and \u0026ldquo;GNU Free Documentation License\u0026rdquo;.\nLicense of bison manual Copyright \u0026copy; 1988, 1989, 1990, 1991, 1992, 1993, 1995, 1998, 1999, 2000, 2001 Free Software Foundation, Inc.\nPermission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies.\nPermission is granted to copy and distribute modified versions of this manual under the conditions for verbatim copying, provided also that the sections entitled \u0026ldquo;GNU General Public License\u0026rdquo; and \u0026ldquo;Conditions for Using Bison\u0026rdquo; are included exactly as in the original, and provided that the entire resulting derived work is distributed under the terms of a permission notice identical to this one.\nPermission is granted to copy and distribute translations of this manual into another language, under the above conditions for modified versions, except that the sections entitled \u0026ldquo;GNU General Public License\u0026rdquo;, \u0026ldquo;Conditions for Using Bison\u0026rdquo; and this permission notice may be included in translations approved by the Free Software Foundation instead of in the original English.\nConditions for Using Bison As of Bison version 1.24, we have changed the distribution terms for yyparse to permit using Bison\u0026rsquo;s output in nonfree programs. Formerly, Bison parsers could be used only in programs that were free software.\nThe other GNU programming tools, such as the GNU C compiler, have never had such a requirement. They could always be used for nonfree software. The reason Bison was different was not due to a special policy decision; it resulted from applying the usual General Public License to all of the Bison source code.\nThe output of the Bison utility\u0026ndash;the Bison parser file\u0026ndash;contains a verbatim copy of a sizable piece of Bison, which is the code for the yyparse function. (The actions from your grammar are inserted into this function at one point, but the rest of the function is not changed.) When we applied the GPL terms to the code for yyparse, the effect was to restrict the use of Bison output to free software.\nWe didn\u0026rsquo;t change the terms because of sympathy for people who want to make software proprietary. Software should be free. But we concluded that limiting Bison\u0026rsquo;s use to free software was doing little to encourage people to make other software free. So we decided to make the practical conditions for using Bison match the practical conditions for using the other GNU tools.\nCopying This Manual GNU Free Documentation License: License for copying bison manual.\nGNU Free Documentation License Copyright \u0026copy; 2000 Free Software Foundation, Inc. 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nPREAMBLE The purpose of this License is to make a manual, textbook, or other functional and useful document \u0026ldquo;free\u0026rdquo; in the sense of freedom: to assure everyone the effective freedom to copy and redistribute it, with or without modifying it, either commercially or noncommercially. Secondarily, this License preserves for the author and publisher a way to get credit for their work, while not being considered responsible for modifications made by others.\nThis License is a kind of \u0026ldquo;copyleft\u0026rdquo;, which means that derivative works of the document must themselves be free in the same sense. It complements the GNU General Public License, which is a copyleft license designed for free software.\nWe have designed this License in order to use it for manuals for free software, because free software needs free documentation: a free program should come with manuals providing the same freedoms that the software does. But this License is not limited to software manuals; it can be used for any textual work, regardless of subject matter or whether it is published as a printed book. We recommend this License principally for works whose purpose is instruction or reference.\nAPPLICABILITY AND DEFINITIONS This License applies to any manual or other work, in any medium, that contains a notice placed by the copyright holder saying it can be distributed under the terms of this License. Such a notice grants a world-wide, royalty-free license, unlimited in duration, to use that work under the conditions stated herein. The \u0026ldquo;Document\u0026rdquo;, below, refers to any such manual or work. Any member of the public is a licensee, and is addressed as \u0026ldquo;you\u0026rdquo;. You accept the license if you copy, modify or distribute the work in a way requiring permission under copyright law.\nA \u0026ldquo;Modified Version\u0026rdquo; of the Document means any work containing the Document or a portion of it, either copied verbatim, or with modifications and/or translated into another language.\nA \u0026ldquo;Secondary Section\u0026rdquo; is a named appendix or a front-matter section of the Document that deals exclusively with the relationship of the publishers or authors of the Document to the Document\u0026rsquo;s overall subject (or to related matters) and contains nothing that could fall directly within that overall subject. (Thus, if the Document is in part a textbook of mathematics, a Secondary Section may not explain any mathematics.) The relationship could be a matter of historical connection with the subject or with related matters, or of legal, commercial, philosophical, ethical or political position regarding them.\nThe \u0026ldquo;Invariant Sections\u0026rdquo; are certain Secondary Sections whose titles are designated, as being those of Invariant Sections, in the notice that says that the Document is released under this License. If a section does not fit the above definition of Secondary then it is not allowed to be designated as Invariant. The Document may contain zero Invariant Sections. If the Document does not identify any Invariant Sections then there are none.\nThe \u0026ldquo;Cover Texts\u0026rdquo; are certain short passages of text that are listed, as Front-Cover Texts or Back-Cover Texts, in the notice that says that the Document is released under this License. A Front-Cover Text may be at most 5 words, and a Back-Cover Text may be at most 25 words.\nA \u0026ldquo;Transparent\u0026rdquo; copy of the Document means a machine-readable copy, represented in a format whose specification is available to the general public, that is suitable for revising the document straightforwardly with generic text editors or (for images composed of pixels) generic paint programs or (for drawings) some widely available drawing editor, and that is suitable for input to text formatters or for automatic translation to a variety of formats suitable for input to text formatters. A copy made in an otherwise Transparent file format whose markup, or absence of markup, has been arranged to thwart or discourage subsequent modification by readers is not Transparent. An image format is not Transparent if used for any substantial amount of text. A copy that is not \u0026ldquo;Transparent\u0026rdquo; is called \u0026ldquo;Opaque\u0026rdquo;.\nExamples of suitable formats for Transparent copies include plain ASCII without markup, Texinfo input format, LaTeX input format, SGML or XML using a publicly available DTD, and standard-conforming simple HTML, PostScript or PDF designed for human modification. Examples of transparent image formats include PNG, XCF and JPG. Opaque formats include proprietary formats that can be read and edited only by proprietary word processors, SGML or XML for which the DTD and/or processing tools are not generally available, and the machine-generated HTML, PostScript or PDF produced by some word processors for output purposes only.\nThe \u0026ldquo;Title Page\u0026rdquo; means, for a printed book, the title page itself, plus such following pages as are needed to hold, legibly, the material this License requires to appear in the title page. For works in formats which do not have any title page as such, \u0026ldquo;Title Page\u0026rdquo; means the text near the most prominent appearance of the work\u0026rsquo;s title, preceding the beginning of the body of the text.\nA section \u0026ldquo;Entitled XYZ\u0026rdquo; means a named subunit of the Document whose title either is precisely XYZ or contains XYZ in parentheses following text that translates XYZ in another language. (Here XYZ stands for a specific section name mentioned below, such as \u0026ldquo;Acknowledgements\u0026rdquo;, \u0026ldquo;Dedications\u0026rdquo;, \u0026ldquo;Endorsements\u0026rdquo;, or \u0026ldquo;History\u0026rdquo;.) To \u0026ldquo;Preserve the Title\u0026rdquo; of such a section when you modify the Document means that it remains a section \u0026ldquo;Entitled XYZ\u0026rdquo; according to this definition.\nThe Document may include Warranty Disclaimers next to the notice which states that this License applies to the Document. These Warranty Disclaimers are considered to be included by reference in this License, but only as regards disclaiming warranties: any other implication that these Warranty Disclaimers may have is void and has no effect on the meaning of this License.\nVERBATIM COPYING You may copy and distribute the Document in any medium, either commercially or noncommercially, provided that this License, the copyright notices, and the license notice saying this License applies to the Document are reproduced in all copies, and that you add no other conditions whatsoever to those of this License. You may not use technical measures to obstruct or control the reading or further copying of the copies you make or distribute. However, you may accept compensation in exchange for copies. If you distribute a large enough number of copies you must also follow the conditions in section 3.\nYou may also lend copies, under the same conditions stated above, and you may publicly display copies.\nCOPYING IN QUANTITY If you publish printed copies (or copies in media that commonly have printed covers) of the Document, numbering more than 100, and the Document\u0026rsquo;s license notice requires Cover Texts, you must enclose the copies in covers that carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on the back cover. Both covers must also clearly and legibly identify you as the publisher of these copies. The front cover must present the full title with all words of the title equally prominent and visible. You may add other material on the covers in addition. Copying with changes limited to the covers, as long as they preserve the title of the Document and satisfy these conditions, can be treated as verbatim copying in other respects.\nIf the required texts for either cover are too voluminous to fit legibly, you should put the first ones listed (as many as fit reasonably) on the actual cover, and continue the rest onto adjacent pages.\nIf you publish or distribute Opaque copies of the Document numbering more than 100, you must either include a machine-readable Transparent copy along with each Opaque copy, or state in or with each Opaque copy a computer-network location from which the general network-using public has access to download using public-standard network protocols a complete Transparent copy of the Document, free of added material. If you use the latter option, you must take reasonably prudent steps, when you begin distribution of Opaque copies in quantity, to ensure that this Transparent copy will remain thus accessible at the stated location until at least one year after the last time you distribute an Opaque copy (directly or through your agents or retailers) of that edition to the public.\nIt is requested, but not required, that you contact the authors of the Document well before redistributing any large number of copies, to give them a chance to provide you with an updated version of the Document.\nMODIFICATIONS You may copy and distribute a Modified Version of the Document under the conditions of sections 2 and 3 above, provided that you release the Modified Version under precisely this License, with the Modified Version filling the role of the Document, thus licensing distribution and modification of the Modified Version to whoever possesses a copy of it. In addition, you must do these things in the Modified Version:\nGNU FDL Modification Conditions\n Use in the Title Page (and on the covers, if any) a title distinct from that of the Document, and from those of previous versions (which should, if there were any, be listed in the History section of the Document). You may use the same title as a previous version if the original publisher of that version gives permission.\n List on the Title Page, as authors, one or more persons or entities responsible for authorship of the modifications in the Modified Version, together with at least five of the principal authors of the Document (all of its principal authors, if it has fewer than five), unless they release you from this requirement.\n State on the Title page the name of the publisher of the Modified Version, as the publisher.\n Preserve all the copyright notices of the Document.\n Add an appropriate copyright notice for your modifications adjacent to the other copyright notices.\n Include, immediately after the copyright notices, a license notice giving the public permission to use the Modified Version under the terms of this License, in the form shown in the Addendum below.\n Preserve in that license notice the full lists of Invariant Sections and required Cover Texts given in the Document\u0026rsquo;s license notice.\n Include an unaltered copy of this License.\n Preserve the section Entitled \u0026ldquo;History\u0026rdquo;, Preserve its Title, and add to it an item stating at least the title, year, new authors, and publisher of the Modified Version as given on the Title Page. If there is no section Entitled \u0026ldquo;History\u0026rdquo; in the Document, create one stating the title, year, authors, and publisher of the Document as given on its Title Page, then add an item describing the Modified Version as stated in the previous sentence.\n Preserve the network location, if any, given in the Document for public access to a Transparent copy of the Document, and likewise the network locations given in the Document for previous versions it was based on. These may be placed in the \u0026ldquo;History\u0026rdquo; section. You may omit a network location for a work that was published at least four years before the Document itself, or if the original publisher of the version it refers to gives permission.\n For any section Entitled \u0026ldquo;Acknowledgements\u0026rdquo; or \u0026ldquo;Dedications\u0026rdquo;, Preserve the Title of the section, and preserve in the section all the substance and tone of each of the contributor acknowledgements and/or dedications given therein.\n Preserve all the Invariant Sections of the Document, unaltered in their text and in their titles. Section numbers or the equivalent are not considered part of the section titles.\n Delete any section Entitled \u0026ldquo;Endorsements\u0026rdquo;. Such a section may not be included in the Modified Version.\n Do not retitle any existing section to be Entitled \u0026ldquo;Endorsements\u0026rdquo; or to conflict in title with any Invariant Section.\n Preserve any Warranty Disclaimers.\n  If the Modified Version includes new front-matter sections or appendices that qualify as Secondary Sections and contain no material copied from the Document, you may at your option designate some or all of these sections as invariant. To do this, add their titles to the list of Invariant Sections in the Modified Version\u0026rsquo;s license notice. These titles must be distinct from any other section titles.\nYou may add a section Entitled \u0026ldquo;Endorsements\u0026rdquo;, provided it contains nothing but endorsements of your Modified Version by various parties\u0026ndash;for example, statements of peer review or that the text has been approved by an organization as the authoritative definition of a standard.\nYou may add a passage of up to five words as a Front-Cover Text, and a passage of up to 25 words as a Back-Cover Text, to the end of the list of Cover Texts in the Modified Version. Only one passage of Front-Cover Text and one of Back-Cover Text may be added by (or through arrangements made by) any one entity. If the Document already includes a cover text for the same cover, previously added by you or by arrangement made by the same entity you are acting on behalf of, you may not add another; but you may replace the old one, on explicit permission from the previous publisher that added the old one.\nThe author(s) and publisher(s) of the Document do not by this License give permission to use their names for publicity for or to assert or imply endorsement of any Modified Version.\nCOMBINING DOCUMENTS You may combine the Document with other documents released under this License, under the terms defined in section 4 above for modified versions, provided that you include in the combination all of the Invariant Sections of all of the original documents, unmodified, and list them all as Invariant Sections of your combined work in its license notice, and that you preserve all their Warranty Disclaimers.\nThe combined work need only contain one copy of this License, and multiple identical Invariant Sections may be replaced with a single copy. If there are multiple Invariant Sections with the same name but different contents, make the title of each such section unique by adding at the end of it, in parentheses, the name of the original author or publisher of that section if known, or else a unique number. Make the same adjustment to the section titles in the list of Invariant Sections in the license notice of the combined work.\nIn the combination, you must combine any sections Entitled \u0026ldquo;History\u0026rdquo; in the various original documents, forming one section Entitled \u0026ldquo;History\u0026rdquo;; likewise combine any sections Entitled \u0026ldquo;Acknowledgements\u0026rdquo;, and any sections Entitled \u0026ldquo;Dedications\u0026rdquo;. You must delete all sections Entitled \u0026ldquo;Endorsements\u0026rdquo;.\nCOLLECTIONS OF DOCUMENTS You may make a collection consisting of the Document and other documents released under this License, and replace the individual copies of this License in the various documents with a single copy that is included in the collection, provided that you follow the rules of this License for verbatim copying of each of the documents in all other respects.\nYou may extract a single document from such a collection, and distribute it individually under this License, provided you insert a copy of this License into the extracted document, and follow this License in all other respects regarding verbatim copying of that document.\nAGGREGATION WITH INDEPENDENT WORKS A compilation of the Document or its derivatives with other separate and independent documents or works, in or on a volume of a storage or distribution medium, is called an \u0026ldquo;aggregate\u0026rdquo; if the copyright resulting from the compilation is not used to limit the legal rights of the compilation\u0026rsquo;s users beyond what the individual works permit. When the Document is included in an aggregate, this License does not apply to the other works in the aggregate which are not themselves derivative works of the Document.\nIf the Cover Text requirement of section 3 is applicable to these copies of the Document, then if the Document is less than one half of the entire aggregate, the Document\u0026rsquo;s Cover Texts may be placed on covers that bracket the Document within the aggregate, or the electronic equivalent of covers if the Document is in electronic form. Otherwise they must appear on printed covers that bracket the whole aggregate.\nTRANSLATION Translation is considered a kind of modification, so you may distribute translations of the Document under the terms of section 4. Replacing Invariant Sections with translations requires special permission from their copyright holders, but you may include translations of some or all Invariant Sections in addition to the original versions of these Invariant Sections. You may include a translation of this License, and all the license notices in the Document, and any Warranty Disclaimers, provided that you also include the original English version of this License and the original versions of those notices and disclaimers. In case of a disagreement between the translation and the original version of this License or a notice or disclaimer, the original version will prevail.\nIf a section in the Document is Entitled \u0026ldquo;Acknowledgements\u0026rdquo;, \u0026ldquo;Dedications\u0026rdquo;, or \u0026ldquo;History\u0026rdquo;, the requirement (section 4) to Preserve its Title (section 1) will typically require changing the actual title.\nTERMINATION You may not copy, modify, sublicense, or distribute the Document except as expressly provided for under this License. Any other attempt to copy, modify, sublicense or distribute the Document is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.\nFUTURE REVISIONS OF THIS LICENSE The Free Software Foundation may publish new, revised versions of the GNU Free Documentation License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns. See http://www.gnu.org/copyleft/.\nEach version of the License is given a distinguishing version number. If the Document specifies that a particular numbered version of this License \u0026ldquo;or any later version\u0026rdquo; applies to it, you have the option of following the terms and conditions either of that specified version or of any later version that has been published (not as a draft) by the Free Software Foundation. If the Document does not specify a version number of this License, you may choose any version ever published (not as a draft) by the Free Software Foundation.\nADDENDUM: How to use this License for your documents(#addendum) To use this License in a document you have written, include a copy of the License in the document and put the following copyright and license notices just after the title page:\nSample Invariant Sections list\nCopyright \u0026copy; YEAR YOUR NAME. Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. A copy of the license is included in the section entitled \u0026ldquo;GNU Free Documentation License\u0026rdquo;.\nIf you have Invariant Sections, Front-Cover Texts and Back-Cover Texts, replace the \u0026ldquo;with\u0026hellip;Texts.\u0026rdquo; line with this:\nSample Invariant Sections list\nwith the Invariant Sections being LIST THEIR TITLES, with the Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST.\nIf you have Invariant Sections without Cover Texts, or some other combination of the three, merge those two alternatives to suit the situation.\nIf your document contains nontrivial examples of program code, we recommend releasing these examples in parallel under your choice of free software license, such as the GNU General Public License, to permit their use in free software.\nGNU General Public License Version 2, June 1991\nCopyright \u0026copy; 1989, 1991 Free Software Foundation, Inc. 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\nPreamble The licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change free software - to make sure the software is free for all its users. This General Public License applies to most of the Free Software Foundation\u0026rsquo;s software and to any other program whose authors commit to using it. (Some other Free Software Foundation software is covered by the GNU Library General Public License instead.) You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things.\nTo protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to surrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the software, or if you modify it.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nWe protect your rights with two steps:\n copyright the software, and\n offer you this license which gives you legal permission to copy, distribute and/or modify the software.\n  Also, for each author\u0026rsquo;s protection and ours, we want to make certain that everyone understands that there is no warranty for this free software. If the software is modified by someone else and passed on, we want its recipients to know that what they have is not the original, so that any problems introduced by others will not reflect on the original authors\u0026rsquo; reputations.\nFinally, any free program is threatened constantly by software patents. We wish to avoid the danger that redistributors of a free program will individually obtain patent licenses, in effect making the program proprietary. To prevent this, we have made it clear that any patent must be licensed for everyone\u0026rsquo;s free use or not licensed at all.\nThe precise terms and conditions for copying, distribution and modification follow.\nTERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION Section 0 This License applies to any program or other work which contains a notice placed by the copyright holder saying it may be distributed under the terms of this General Public License. The \u0026ldquo;Program\u0026rdquo;, below, refers to any such program or work, and a \u0026ldquo;work based on the Program \u0026rdquo; means either the Program or any derivative work under copyright law: that is to say, a work containing the Program or a portion of it, either verbatim or with modifications and/or translated into another language. (Hereinafter, translation is included without limitation in the term \u0026ldquo;modification \u0026ldquo;.) Each licensee is addressed as \u0026ldquo;you\u0026rdquo;.\nActivities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running the Program is not restricted, and the output from the Program is covered only if its contents constitute a work based on the Program (independent of having been made by running the Program). Whether that is true depends on what the Program does.\nSection 1 You may copy and distribute verbatim copies of the Program\u0026rsquo;s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and give any other recipients of the Program a copy of this License along with the Program.\nYou may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.\nSection 2 You may modify your copy or copies of the Program or any portion of it, thus forming a work based on the Program, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:\n You must cause the modified files to carry prominent notices stating that you changed the files and the date of any change.\n You must cause any work that you distribute or publish, that in whole or in part contains or is derived from the Program or any part thereof, to be licensed as a whole at no charge to all third parties under the terms of this License.\n If the modified program normally reads commands interactively when run, you must cause it, when started running for such interactive use in the most ordinary way, to print or display an announcement including an appropriate copyright notice and a notice that there is no warranty (or else, saying that you provide a warranty) and that users may redistribute the program under these conditions, and telling the user how to view a copy of this License.\n   Exception: If the Program itself is interactive but does not normally print such an announcement, your work based on the Program is not required to print an announcement.)\n These requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Program, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Program, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.\nThus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Program.\nIn addition, mere aggregation of another work not based on the Program with the Program (or with a work based on the Program) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.\nSection 3 You may copy and distribute the Program (or a work based on it, under Section 2 in object code or executable form under the terms of Sections 1 and 2 above provided that you also do one of the following:\n Accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\n Accompany it with a written offer, valid for at least three years, to give any third party, for a charge no more than your cost of physically performing source distribution, a complete machine-readable copy of the corresponding source code, to be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\n Accompany it with the information you received as to the offer to distribute corresponding source code. (This alternative is allowed only for noncommercial distribution and only if you received the program in object code or executable form with such an offer, in accord with Subsection b above.)\n  The source code for a work means the preferred form of the work for making modifications to it. For an executable work, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the executable. However, as a special exception, the source code distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.\nIf distribution of executable or object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place counts as distribution of the source code, even though third parties are not compelled to copy the source along with the object code.\nSection 4 You may not copy, modify, sublicense, or distribute the Program except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense or distribute the Program is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.\nSection 5 You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Program or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Program (or any work based on the Program), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Program or works based on it.\nSection 6 Each time you redistribute the Program (or any work based on the Program), the recipient automatically receives a license from the original licensor to copy, distribute or modify the Program subject to these terms and conditions. You may not impose any further restrictions on the recipients\u0026rsquo; exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties to this License.\nSection 7 If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Program at all. For example, if a patent license would not permit royalty-free redistribution of the Program by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Program.\nIf any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply and the section as a whole is intended to apply in other circumstances.\nIt is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system, which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.\nThis section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.\nSection 8 If the distribution and/or use of the Program is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Program under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License.\nSection 9 The Free Software Foundation may publish revised and/or new versions of the General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies a version number of this License which applies to it and \u0026ldquo;any later version\u0026rdquo;, you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of this License, you may choose any version ever published by the Free Software Foundation.\nSection 10 If you wish to incorporate parts of the Program into other free programs whose distribution conditions are different, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.\nNO WARRANTY Section 11 BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \u0026ldquo;AS IS\u0026rdquo; WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\nSection 12 IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\nEND OF TERMS AND CONDITIONS\nHow to Apply These Terms to Your New Programs If you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the \u0026ldquo;copyright\u0026rdquo; line and a pointer to where the full notice is found.\n\u0026lt;one line to give the program's name and a brief idea of what it does.\u0026gt; Copyright (C) \u0026lt;year\u0026gt; \u0026lt;name of author\u0026gt;  This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\nAlso add information on how to contact you by electronic and paper mail.\nIf the program is interactive, make it output a short notice like this when it starts in an interactive mode:\n Gnomovision version 69, Copyright (C) year name of author Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details.  The hypothetical commands \u0026lsquo;show w\u0026rsquo; and \u0026lsquo;show c\u0026rsquo; should show the appropriate parts of the General Public License. Of course, the commands you use may be called something other than \u0026lsquo;show w\u0026rsquo; and \u0026lsquo;show c\u0026rsquo;; they could even be mouse-clicks or menu items\u0026ndash;whatever suits your program.\nYou should also get your employer (if you work as a programmer) or your school, if any, to sign a \u0026ldquo;copyright disclaimer\u0026rdquo; for the program, if necessary. Here is a sample; alter the names:\nYoyodyne, Inc., hereby disclaims all copyright interest in the program 'Gnomovision' (which makes passes at compilers) written by James Hacker. \u0026lt;signature of Ty Coon\u0026gt;, 1 April 1989 Ty Coon, President of Vice  This General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Library General Public License instead of this License.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/grammaroutline/",
	"title": "Grammar outline",
	"tags": [],
	"description": "A Ocamlyacc grammar file has four main sections, shown here with the appropriate delimiters:",
	"content": " A Ocamlyacc grammar file has four main sections, shown here with the appropriate delimiters:\n%{ Header - Ocaml declarations (Ocaml code) %} Ocamlyacc declarations %% Grammar rules %% Trailer - Additional Ocaml code (Ocaml code)  By default, comments are enclosed between /* and / (as in C) except in Ocaml code. So use / and / in the declarations and rules sections, ( and *) in header and trailer sections.\nThe Header Section The header section contains declarations of functions and variables that are used in the actions in the grammar rules. These are copied to the beginning of the parser file so that they precede the definition of the parser function. You can open the other module in this area. If you don\u0026rsquo;t need any Ocaml declarations, you may omit the %{ and %} delimiters that bracket this section.\nThe Ocamlyacc Declarations Section The ocamlyacc declarations section contains declarations that define terminal and nonterminal symbols, specify precedence, and so on. At least, there must be one %start and the corresponding %type directives. See Ocamlyacc declarations.\nThe Grammar Rules Section The grammar rules section contains one or more Ocamlyacc grammar rules, and nothing else. See Syntax of Grammar Rules.\nThere must always be at least one grammar rule, and the first %% (which precedes the grammar rules) may never be omitted even if it is the first thing in the file.\nThe Trailer Section The trailer section is copied verbatim to the end of the parser file, just as the header section is copied to the beginning. This is the most convenient place to put anything that you want to have in the parser file but which need not come before the definition of the parse function. See Parser Interface.\nIf the last section is empty, you may omit the %% that separates it from the grammar rules.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Ocamlyacc is a general-purpose parser generator that converts a grammar description for an LALR(1) context-free grammar into a Ocaml program to parse that grammar. Once you are proficient with Ocamlyacc, you may use it to develop a wide range of language parsers, from those used in simple desk calculators to complex programming languages.\nOcamlyacc is very close to the well-known yacc (or bison) commands that can be found in most C programming environments. Anyone familiar with Yacc should be able to use Ocamlyacc with little trouble. You need to be fluent in Ocaml programming in order to use Ocamlyacc or to understand this manual.\nWe begin with tutorial chapters that explain the basic concepts of using Ocamlyacc and show three explained examples, each building on the last. If you don\u0026rsquo;t know Ocamlyacc or Yacc, start by reading these chapters. Reference chapters follow which describe specific aspects of Ocamlyacc in detail.\nSome explanation is not suitable for the earlier version than 3.08 of Ocaml (Ocamlyacc), in that case, there will be comments like \u0026ldquo;(Since Ocaml 3.08)\u0026rdquo;.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/languagsandcfg/",
	"title": "Languages and context-free grammars",
	"tags": [],
	"description": "In order for Ocamlyacc to parse a language, it must be described by a context-free grammar.",
	"content": "In order for Ocamlyacc to parse a language, it must be described by a context-free grammar. This means that you specify one or more syntactic groupings and give rules for constructing them from their parts. For example, in the C language, one kind of grouping is called an \u0026lsquo;expression\u0026rsquo;. One rule for making an expression might be, \u0026ldquo;An expression can be made of a minus sign and another expression\u0026rdquo;. Another would be, \u0026ldquo;An expression can be an integer\u0026rdquo;. As you can see, rules are often recursive, but there must be at least one rule which leads out of the recursion.\nThe most common formal system for presenting such rules for humans to read is Backus-Naur Form or BNF, which was developed in order to specify the language Algol 60. Any grammar expressed in BNF is a context-free grammar. The input to Ocamlyacc is essentially machine-readable BNF.\nNot all context-free languages can be handled by Ocamlyacc, only those that are LALR(1). In brief, this means that it must be possible to tell how to parse any portion of an input string with just a single token of look-ahead. Strictly speaking, that is a description of an LR(1) grammar, and LALR(1) involves additional restrictions that are hard to explain simply; but it is rare in actual practice to find an LR(1) grammar that fails to be LALR(1). See Mysterious Reduce/Reduce Conflicts, for more information on this.\nIn the formal grammatical rules for a language, each kind of syntactic unit or grouping is named by a symbol. Those which are built by grouping smaller constructs according to grammatical rules are called nonterminal symbols; those which can\u0026rsquo;t be subdivided are called terminal symbols or token types. We call a piece of input corresponding to a single terminal symbol a \u0026ldquo;token\u0026rdquo;, and a piece corresponding to a single nonterminal symbol a grouping.\nWe can use the C language as an example of what symbols, terminal and nonterminal, mean. The tokens of C are identifiers, constants (numeric and string), and the various keywords, arithmetic operators and punctuation marks. So the terminal symbols of a grammar for C include \u0026lsquo;identifier\u0026rsquo;, \u0026lsquo;number\u0026rsquo;, \u0026lsquo;string\u0026rsquo;, plus one symbol for each keyword, operator or punctuation mark: \u0026lsquo;if\u0026rsquo;, \u0026lsquo;return\u0026rsquo;, \u0026lsquo;const\u0026rsquo;, \u0026lsquo;static\u0026rsquo;, \u0026lsquo;int\u0026rsquo;, \u0026lsquo;char\u0026rsquo;, \u0026lsquo;plus-sign\u0026rsquo;, \u0026lsquo;open-brace\u0026rsquo;, \u0026lsquo;close-brace\u0026rsquo;, \u0026lsquo;comma\u0026rsquo; and many more. (These tokens can be subdivided into characters, but that is a matter of lexicography, not grammar.)\nHere is a simple C function subdivided into tokens:\n\u0026rdquo;\u0026lsquo;C int /* keyword \u0026lsquo;int\u0026rsquo; / square (int x) / identifier, open-paren, identifier, identifier, close-paren / { / open-brace */ return x * x; /* keyword \u0026lsquo;return\u0026rsquo;, identifier, asterisk, identifier, semicolon / } / close-brace */ \u0026ldquo;\u0026rsquo;\nThe syntactic groupings of C include the expression, the statement, the declaration, and the function definition. These are represented in the grammar of C by nonterminal symbols \u0026lsquo;expression\u0026rsquo;, \u0026lsquo;statement\u0026rsquo;, \u0026lsquo;declaration\u0026rsquo; and \u0026lsquo;function definition\u0026rsquo;. The full grammar uses dozens of additional language constructs, each with its own nonterminal symbol, in order to express the meanings of these four. The example above is a function definition; it contains one declaration, and one statement. In the statement, each \u0026ldquo;x\u0026rdquo; is an expression and so is \u0026ldquo;x * x\u0026rdquo;.\nEach nonterminal symbol must have grammatical rules showing how it is made out of simpler constructs. For example, one kind of C statement is the \u0026ldquo;return\u0026rdquo; statement; this would be described with a grammar rule which reads informally as follows:\nA 'statement' can be made of a 'return' keyword, an 'expression' and a 'semicolon'.  There would be many other rules for \u0026lsquo;statement\u0026rsquo;, one for each kind of statement in C.\nOne nonterminal symbol must be distinguished as the special one which defines a complete utterance in the language. It is called the start symbol. In a compiler, this means a complete input program. In the C language, the nonterminal symbol \u0026lsquo;sequence of definitions and declarations\u0026rsquo; plays this role.\nFor example, \u0026ldquo;1 + 2\u0026rdquo; is a valid C expression\u0026mdash;a valid part of a C program\u0026mdash;but it is not valid as an entire C program. In the context-free grammar of C, this follows from the fact that \u0026lsquo;expression\u0026rsquo; is not the start symbol.\nThe Ocamlyacc parser reads a sequence of tokens as its input, and groups the tokens using the grammar rules. If the input is valid, the end result is that the entire token sequence reduces to a single grouping whose symbol is the grammar\u0026rsquo;s start symbol. If we use a grammar for C, the entire input must be a \u0026lsquo;sequence of definitions and declarations\u0026rsquo;. If not, the parser reports a syntax error.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/lookaheadtokens/",
	"title": "Lookahead Tokens",
	"tags": [],
	"description": "The Ocamlyacc parser does not always reduce immediately as soon as the last n tokens and groupings match a rule.",
	"content": "The Ocamlyacc parser does not always reduce immediately as soon as the last n tokens and groupings match a rule. This is because such a simple strategy is inadequate to handle most languages. Instead, when a reduction is possible, the parser sometimes \u0026ldquo;looks ahead\u0026rdquo; at the next token in order to decide what to do.\nWhen a token is read, it is not immediately shifted; first it becomes the look-ahead token, which is not on the stack. Now the parser can perform one or more reductions of tokens and groupings on the stack, while the look-ahead token remains off to the side. When no more reductions should take place, the look-ahead token is shifted onto the stack. This does not mean that all possible reductions have been done; depending on the token type of the look-ahead token, some rules may choose to delay their application.\nHere is a simple case where look-ahead is needed. These three rules define expressions which contain binary addition operators and postfix unary factorial operators (FACTORIAL for \u0026lsquo;!\u0026rsquo;), and allow parentheses for grouping.\nexpr: term PLUS expr | term ; term: LPAREN expr RPAREN | term FACTORIAL | NUMBER ;  Suppose that the tokens 1 + 2 have been read and shifted; what should be done? If the following token is RPAREN, then the first three tokens must be reduced to form an expr. This is the only valid course, because shifting the RPAREN would produce a sequence of symbols term RPAREN, and no rule allows this.\nIf the following token is FACTORIAL, that is \u0026lsquo;!\u0026rsquo;, then it must be shifted immediately so that 2 ! can be reduced to make a term. If instead the parser were to reduce before shifting, 1 + 2 would become an expr. It would then be impossible to shift the ! because doing so would produce on the stack the sequence of symbols expr FACTORIAL. No rule allows that sequence.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/options/",
	"title": "Options",
	"tags": [],
	"description": "",
	"content": "ocamllex has the following options:\n \u0026rdquo;-o output-file\u0026rdquo;  \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; By default, ocamllex produces lexer.ml, when ocamllex is invoked as \u0026ldquo;ocamllex lexer.mll\u0026rdquo;. You can change the name of the output file using -o option.\n \u0026rdquo;-ml\u0026rdquo;  \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; By default, ocamllex produces code that uses the Caml built-in automata interpreter. Using this option, the automaton is coded as Caml functions. This option is useful for debugging ocamllex, but it\u0026rsquo;s not recommended for production lexers.\n \u0026rdquo;-q\u0026rdquo;  \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; By default, ocamllex outputs informational messages to standard output. If you use -q option, they are suppressed.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/invokingocamlyacc/options/",
	"title": "Options",
	"tags": [],
	"description": "Ocamlyacc options",
	"content": "Here is a list of options that can be used with Ocamlyacc:\n -v: By default, this option generates a file grammar.output. It contains parsing infomation such as a description of the parsing tables and a report on ambiguities in the grammar.\n -bfname: Change the name of the output files to fname.ml, fname.mli and fname.output.\n  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parserinterface/parserfunctions/",
	"title": "Parser Functions",
	"tags": [],
	"description": "To cause parsing to occur, you call the parser function with two parameters.",
	"content": "To cause parsing to occur, you call the parser function with two parameters. The first parameter is the lexical analyzer function of type\nLexing.lexbuf -\u0026gt; token  and the second is a value of Lexing.lexbuf type.\nIf the start symbol is parse in the file parser.mly and the lexer function is is token of the file lexer.mll, the typical usage is:\nlet lexbuf = Lexing.from_channel stdin in ... let result = Parser.parse Lexer.token lexbuf in ...  This parser function reads tokens, executes actions, and ultimately returns when it encounters end-of-input or an unrecoverable syntax error.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/examples/reverspolishcalculator/",
	"title": "Reverse Polish Notation Calculator",
	"tags": [],
	"description": "Reverse Polish Notation Calculator: rpcalc",
	"content": " The first example is that of a simple double-precision reverse polish notation calculator (a calculator using postfix operators). This example provides a good starting point, since operator precedence is not an issue. The second example will illustrate how operator precedence is handled.\nThe source code for this calculator is named rpcalc.mly. The .mly extension is a convention used for Ocamlyacc input files.\nDeclarations for \u0026ldquo;rpcalc\u0026rdquo; Here are the Ocaml and Ocamlyacc declarations for the reverse polish notation calculator. By default, comments are enclosed between /* and */ (as in C) except in Ocaml code.\n/* file: rpcalc.mly */ /* Reverse polish notation calculator. */ %{ open Printf %} %token \u0026lt;float\u0026gt; NUM %token PLUS MINUS MULTIPLY DIVIDE CARET UMINUS %token NEWLINE %start input %type \u0026lt;unit\u0026gt; input %% /* Grammar rules and actions follow */  The header section (see The Header Section) has a code of openning \u0026ldquo;Printf\u0026rdquo; module.\nThe second section, Ocamlyacc declarations, provides information to Ocamlyacc about the token types (see The Ocamlyacc Declarations Section). Each terminal must be declared here. The first terminal symbol is the token type for numeric constants which has a value of float The possible arithmetic operators are PLUS, MINUS, MULTIPLY, DIVIDE, CARET for exponetiation and UMINUS for unary minus. These operator terminals don\u0026rsquo;t have any value with it. The last terminal is NEWLINE, a token type for the newline character.\nYou must give the names of the start symbols and their types, too. In this examples, there is one start symbol named input which has type of unit. For each start symbol, the parser function with the same name is generated.\nGrammar Rules for rpcalc Here are the grammar rules for the reverse polish notation calculator.\ninput: /* empty */\t{ } | input line\t{ } ; line: NEWLINE\t{ } | exp NEWLINE\t{ printf \u0026quot;\\t%.10g\\n\u0026quot; $1; flush stdout } ; exp: NUM\t{ $1 } | exp exp PLUS\t{ $1 +. $2 } | exp exp MINUS\t{ $1 -. $2 } | exp exp MULTIPLY\t{ $1 *. $2 } | exp exp DIVIDE\t{ $1 /. $2 } /* Exponentiation */ | exp exp CARET\t{ $1 ** $2 } /* Unary minus */ | exp UMINUS\t{ -. $1 } ; %%  The groupings of the rpcalc \u0026ldquo;language\u0026rdquo; defined here are the expression (given the name exp), the line of input (line), and the complete input transcript (input). Each of these nonterminal symbols has several alternate rules, joined by the | punctuator which is read as \u0026ldquo;or\u0026rdquo;. The following sections explain what these rules mean.\nThe semantics of the language is determined by the actions taken when a grouping is recognized. The actions are the Ocaml code that appears inside braces. See Actions.\nYou must specify these actions in Ocaml, but Ocamlyacc provides the means for passing semantic values between the rules. In each action, the semantic value for the grouping that the rule is going to construct should be given. The semantic values of the components of the rule are referred to as $1, $2, and so on.\nExplanation of input Consider the definition of input:\ninput: /* empty */ | input line ;  This definition reads as follows: \u0026ldquo;A complete input is either an empty string, or a complete input followed by an input line\u0026rdquo;. Notice that \u0026ldquo;complete input\u0026rdquo; is defined in terms of itself. This definition is said to be left recursive since input appears always as the leftmost symbol in the sequence. See Recursive Rules.\nThe first alternative is empty because there are no symbols between the colon and the first |; this means that input can match an empty string of input (no tokens). We write the rules this way because it is legitimate to type Ctrl-d right after you start the calculator. It\u0026rsquo;s conventional to put an empty alternative first and write the comment /* empty */ in it.\nThe second alternate rule (input line) handles all nontrivial input. It means, \u0026ldquo;After reading any number of lines, read one more line if possible.\u0026rdquo; The left recursion makes this rule into a loop. Since the first alternative matches empty input, the loop can be executed zero or more times.\nThe parser function input continues to process input until a grammatical error is seen or the lexical analyzer says there are no more input tokens; we will arrange for the latter to happen at end of file.\nExplanation of line Now consider the definition of line:\nline: NEWLINE { } | exp NEWLINE { printf \u0026quot;\\t%.10g\\n\u0026quot; $1; flush stdout } ;  The first alternative is a token which is a newline character; this means that rpcalc accepts a blank line (and ignores it, since there is no action). The second alternative is an expression followed by a newline. This is the alternative that makes rpcalc useful. The semantic value of the exp grouping is the value of $1 because the exp in question is the first symbol in the alternative. The action prints this value, which is the result of the computation the user asked for.\nAs you can see, the semantic value associated with the line is unit.\nExplanation of expr The exp grouping has several rules, one for each kind of expression. The first rule handles the simplest expressions: those that are just numbers. The second handles an addition-expression, which looks like two expressions followed by a plus-sign. The third handles subtraction, and so on.\nexp:\tNUM\t{ $1 } | exp exp PLUS\t{ $1 +. $2 } | exp exp MINUS\t{ $1 -. $2 } ... ;  We have used | to join all the rules for exp, but we could equally well have written them separately:\nexp:\tNUM\t{ $1 }; exp:\texp exp PLUS\t{ $1 +. $2 }; exp:\texp exp MINUS\t{ $1 -. $2 }; ...  All of the rules have actions that compute the value of the expression in terms of the value of its parts. For example, in the rule for addition, $1 refers to the first component exp and $2 refers to the second one. The third component, PLUS, has no meaningful associated semantic value, but if it had one you could refer to it as $3. When the parser function recognizes a sum expression using this rule, the sum of the two subexpressions\u0026rsquo; values is produced as the value of the entire expression. See Actions.\nThe formatting shown here is the recommended convention, but Ocamlyacc does not require it. You can add or change whitespace as much as you wish. For example, this:\nexp:\tNUM { $1 } | exp exp PLUS { $1 +. $2 } | ...  means the same thing as this:\nexp: NUM\t{ $1 } | exp exp PLUS\t{ $1 + $2 } | ...  The latter, however, is much more readable.\nThe rpcalc Lexical Analyzer The lexical analyzer\u0026rsquo;s job is low-level parsing: converting characters or sequences of characters into tokens. The Ocamlyacc parser gets its tokens by calling the lexical analyzer. See The Lexical Analyzer Function.\nOnly a simple lexical analyzer is needed for the RPN calculator. This lexical analyzer reads in numbers as float and returns them as NUM tokens. It recognizes \u0026lsquo;+\u0026rsquo;, \u0026lsquo;-\u0026rsquo;, \u0026lsquo;*\u0026lsquo;, \u0026lsquo;/\u0026rsquo;, \u0026lsquo;^\u0026rsquo;, \u0026lsquo;n\u0026rsquo; as operators and returns the corresponding token: ADD, MINUS, MULTIPLY, DIVIDE, CARET and UMINUS. When it meets \u0026lsquo;\\n\u0026rsquo;, the returning token is NEWLINE. Spaces and unknown characers are skipped.\nThe return value of the lexical analyzer function is a value of the concrete token type. The same text used in Ocamlyacc rules to stand for this token type is also a Ocaml expression for the value for the type. Token type is defined by Ocamlyacc as a constructor of the concrete token type. In this example, therefore, NUM, PLUS, \u0026hellip; become values for the lexer function to use.\nThe semantic value of the token (if it has one) is returned with it. In this example, only NUM has a semantic value.\nHere is the code for the lexical analyzer:\n(* file: lexer.mll *) (* Lexical analyzer returns one of the tokens: the token NUM of a floating point number, operators (PLUS, MINUS, MULTIPLY, DIVIDE, CARET, UMINUS), or NEWLINE. It skips all blanks and tabs, unknown characters and raises End_of_file on EOF. *) { open Rtcalc (* Assumes the parser file is \u0026quot;rtcalc.mly\u0026quot;. *) } let digit = ['0'-'9'] rule token = parse | [' ' '\\t']\t{ token lexbuf } | '\\n'\t{ NEWLINE } | digit+ | \u0026quot;.\u0026quot; digit+ | digit+ \u0026quot;.\u0026quot; digit* as num { NUM (float_of_string num) } | '+'\t{ PLUS } | '-'\t{ MINUS } | '*'\t{ MULTIPLY } | '/'\t{ DIVIDE } | '^'\t{ CARET } | 'n'\t{ UMINUS } | _\t{ token lexbuf } | eof\t{ raise End_of_file }  The Controlling Function In keeping with the spirit of this example, the controlling function is kept to the bare minimum. To start the process of parsings, the only requirement is that it call parser function Parser.input with two argumenst: lexical analyzer function Lexer.token and lexbuf of Lexing.lexbuf type.\n(* file: main.ml *) (* Assumes the parser file is \u0026quot;rtcalc.mly\u0026quot; and the lexer file is \u0026quot;lexer.mll\u0026quot;. *) let main () = try let lexbuf = Lexing.from_channel stdin in while true do Rtcalc.input Lexer.token lexbuf done with End_of_file -\u0026gt; exit 0 let _ = Printexc.print main ()  The Error Reporting Routine When ther parser function detects a syntax error, it calls a function named parse_error with the string \u0026ldquo;syntax error\u0026rdquo; as argument. The default parse_error function does nothing and returns, thus initiating error recovery (see Error Recovery). The user can define a customized parse_error function in the header section of the grammar file such as:\nlet parse_error s = (* Called by the parser function on error *) print_endline s; flush stdout  After parse_error returns, the Ocamlyacc parser may recover from the error and continue parsing if the grammar contains a suitable error rule (see Error Recovery). Otherwise, the parser aborts by raising the Parsing.Parse_error exception. We have not written any error rules in this example, so any invalid input will cause the calculator program to raise exception. This is not clean behavior for a real calculator, but it is adequate for the first example.\nRunning Ocamlyacc to Make the Parser Before running Ocamlyacc to produce a parser, we need to decide how to arrange all the source code in source files. For our example, we make three files: rpcalc.mly for Ocamlyacc grammar file, lexer.mll for Ocamllex input file, main.ml which contains main function which calls our parser function.\nYou can use the following command to convert the parser grammar file into a parser file:\nocamlyacc file_name.mly  In this example the file was called rpcalc.mly (for \u0026ldquo;Reverse Polish CALCulator\u0026rdquo;). Ocamlyacc produces a file named file_name.ml. The file output by Ocamlyacc contains the source code for parser function input. The additional functions in the input file (parse_error) are copied verbatim to the output.\nCompiling the Parser File Here is how to compile and run the parser file and lexer file:\n# List files in current directory. $ ls .depend Makefile lexer.mll main.ml rpcalc.mly # Compile the Ocamlyacc parser. $ make ocamlyacc rpcalc.mly ocamlc -c rpcalc.mli ocamllex lexer.mll 15 states, 304 transitions, table size 1306 bytes ocamlc -c lexer.ml ocamlc -c rpcalc.ml ocamlc -c main.ml ocamlc -o rpcalc lexer.cmo rpcalc.cmo main.cmo rm rpcalc.mli lexer.ml rpcalc.ml # List files again. $ ls ./ .depend lexer.cmo main.cmi main.ml rpcalc.cmi rpcalc.mly ../ Makefile lexer.cmi lexer.mll main.cmo rpcalc*\trpcalc.cmo  The file rpcalc now contains the executable code. Here is an example session using rpcalc.\n$ rpcalc 4 9 + 13 3 7 + 3 4 5 *+- -13 3 7 + 3 4 5 * + - n\tNote the unary minus, n 13 5 6 / 4 n + -3.166666667 3 4 ^\tExponentiation 81 ^D\tEnd-of-file indicator $  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/usagetips/",
	"title": "Usage tips",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/examples/",
	"title": "Examples",
	"tags": [],
	"description": "",
	"content": "This chapter includes examples in complete form. Some are revised from the code fragments of the previous chapters.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamllex-tutorial/license/",
	"title": "13. License",
	"tags": [],
	"description": "",
	"content": " Introduction Ocamlyacc is a general-purpose parser generator that converts a grammar description for an LALR(1) context-free grammar into a Ocaml program to parse that grammar. Once you are proficient with Ocamlyacc, you may use it to develop a wide range of language parsers, from those used in simple desk calculators to complex programming languages.\nOcamlyacc is very close to the well-known yacc (or bison) commands that can be found in most C programming environments. Anyone familiar with Yacc should be able to use Ocamlyacc with little trouble. You need to be fluent in Ocaml programming in order to use Ocamlyacc or to understand this manual.\nWe begin with tutorial chapters that explain the basic concepts of using Ocamlyacc and show three explained examples, each building on the last. If you don\u0026rsquo;t know Ocamlyacc or Yacc, start by reading these chapters. Reference chapters follow which describe specific aspects of Ocamlyacc in detail.\nSome explanation is not suitable for the earlier version than 3.08 of Ocaml (Ocamlyacc), in that case, there will be comments like \u0026ldquo;(Since Ocaml 3.08)\u0026rdquo;.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/",
	"title": "Concepts of ocamlyacc",
	"tags": [],
	"description": "",
	"content": "This chapter introduces many of the basic concepts without which the details of Ocamlyacc will not make sense. If you do not already know how to use Ocamlyacc, we suggest you start by reading this chapter carefully.\n Languages and context-free grammars  In order for Ocamlyacc to parse a language, it must be described by a context-free grammar.\n From Foraml Rules to Ocamlyacc Input  A formal grammar is a mathematical construct. To define the language for Ocamlyacc, you must write a file expressing the grammar in Ocamlyacc syntax.\n Semantic values  A formal grammar is a mathematical construct. To define the language for Ocamlyacc, you must write a file expressing the grammar in Ocamlyacc syntax.\n Semantic actions  A grammar rule can have an action made up of Ocaml statements. Each time the parser recognizes a match for that rule, the action is executed.\n Locations  Locations in order to keep track of the textual position, or location, of each syntactic construct.\n Ocamlyacc output  When you run Ocamlyacc, you give it a Ocamlyacc grammar file as input. The output is a Ocaml source file that parses the language described by the grammar.\n Stages in use ocamlyacc  The actual language-design process using Ocamlyacc, from grammar specification to a working compiler or interpreter, has these parts:\n Overall layout of grammar  The general form of a Ocamlyacc grammar file is as follows:\n "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/license/copyright/",
	"title": "Copyright and permission",
	"tags": [],
	"description": "Copyright and Permission",
	"content": "Copyright \u0026copy; 2004-2019 SooHyoung Oh.\nPermission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies.\nPermission is granted to copy and distribute modified versions of this document under the conditions for verbatim copying, provided that this copyright notice is included exactly as in the original, and that the entire resulting derived work is distributed under the terms of a permission notice identical to this one.\nPermission is granted to copy and distribute translations of this document into another language, under the above conditions for modified versions.\nIf you are intending to incorporate this document into a published work, please contact the maintainer, and we will make an effort to ensure that you have the most up to date information available.\nThere is no guarantee that this document lives up to its intended purpose. This is simply provided as a free resource. As such, the authors and maintainers of the information provided within can not make any guarantee that the information is even accurate.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/formalrule/",
	"title": "From Foraml Rules to Ocamlyacc Input",
	"tags": [],
	"description": "A formal grammar is a mathematical construct. To define the language for Ocamlyacc, you must write a file expressing the grammar in Ocamlyacc syntax.",
	"content": "A formal grammar is a mathematical construct. To define the language for Ocamlyacc, you must write a file expressing the grammar in Ocamlyacc syntax: a Ocamlyacc grammar file. See Ocamlyacc Grammar Files.\nA nonterminal symbol in the formal grammar is represented in Ocamlyacc input as an identifier, like an identifier in Ocaml. It is like regular Caml symbol, except that it cannot end with \u0026lsquo; (single quote). It should start in lower case, such as expr, stmt or declaration.\nThe Ocamlyacc representation for a terminal symbol is also called a token types. Token typess should be declared in Ocamlyacc Declaration Section and they are added as constructors for the token concrete type. As constructors, they should start with upper case: for example, Integer, Identifier, IF or RETURN. The terminal symbol error is reserved for error recovery. See Symbols.\nThe grammar rules also have an expression in Ocamlyacc syntax. For example, here is the Ocamlyacc rule for a C return statement.\nstmt: RETURN expr SEMICOLON ;  See Syntax of Grammar Rules.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/examples/infixcalculator/",
	"title": "Infix Notation Calculator",
	"tags": [],
	"description": "Infix Notation Calculator: calc",
	"content": "We now modify rpcalc to handle infix operators instead of postfix. Infix notation involves the concept of operator precedence and the need for parentheses nested to arbitrary depth. Here is the Ocamlyacc code for calc.mly, an infix desk-top calculator.\n/* file: calc.mly */ /* Infix notatoin calculator -- calc */ %{ open Printf %} /* Ocamlyacc Declarations */ %token NEWLINE %token LPAREN RPAREN %token \u0026lt;float\u0026gt; NUM %token PLUS MINUS MULTIPLY DIVIDE CARET %left PLUS MINUS %left MULTIPLY DIVIDE %left NEG\t/* negation -- unary minus */ %right CARET\t/* exponentiation */ %start input %type \u0026lt;unit\u0026gt; input /* Grammar follows */ %% input:\t/* empty */\t{ } | input line\t{ } ; line:\tNEWLINE\t{ } | exp NEWLINE\t{ printf \u0026quot;\\t%.10g\\n\u0026quot; $1; flush stdout } ; exp:\tNUM\t{ $1 } | exp PLUS exp\t{ $1 +. $3 } | exp MINUS exp\t{ $1 -. $3 } | exp MULTIPLY exp\t{ $1 *. $3 } | exp DIVIDE exp\t{ $1 /. $3 } | MINUS exp %prec NEG\t{ -. $2 } | exp CARET exp\t{ $1 ** $3 } | LPAREN exp RPAREN\t{ $2 } ; %%  There are two important new features shown in this code.\nIn the second section (Ocamlyacc declarations), %left says they are left-associative operators. The declarations %left and %right (right associativity) is used for the declaration of associativity.\nOperator precedence is determined by the line ordering of the declarations; the higher the line number of the declaration (lower on the page or screen), the higher the precedence. Hence, exponentiation has the highest precedence, unary minus (NEG) is next, followed by MULTIPLY and DIVIDE, and so on. See Operator Precedence.\nThe other important new feature is the %prec in the grammar section for the unary minus operator. The %prec simply instructs Ocamlyacc that the rule | MINUS exp has the same precedence as NEG\u0026mdash;in this case the next-to-highest. See Context-Dependent Precedence.\nHere is a sample run of calc.mly:\n$ calc 4 + 4.5 - (34/(8*3+-3)) 6.880952381 -56 + 2 -54 3 ^ 2 9  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parserinterface/lexicalfunctions/",
	"title": "Lexical Functions",
	"tags": [],
	"description": "The lexical analyzer function, named after rule declarations, recognizes tokens from the input stream and returns them to the parser.",
	"content": "The lexical analyzer function, named after rule declarations, recognizes tokens from the input stream and returns them to the parser. Ocamlyacc does not create this function automatically; you must write it so that parser function can call it. The function is sometimes referred to as a lexical scanner.\nThis function is usually generated by ocamllex. See Chapter 12 Lexer and parser generators (ocamllex, ocamlyacc).\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/operatorprecedence/",
	"title": "Operator Precedence",
	"tags": [],
	"description": "the Ocamlyacc declarations for operator precedence allow you to specify when to shift and when to reduce.",
	"content": " Another situation where shift/reduce conflicts appear is in arithmetic expressions. Here shifting is not always the preferred resolution; the Ocamlyacc declarations for operator precedence allow you to specify when to shift and when to reduce.\nWhen Precedence is Needed Consider the following ambiguous grammar fragment (ambiguous because the input 1 - 2 * 3 can be parsed in two different ways):\nexpr: expr MINUS expr | expr MULTIPLY expr | expr LT expr | LPAREN expr RPAREN ... ;  Suppose the parser has seen the tokens 1, - and 2; should it reduce them via the rule for the subtraction operator? It depends on the next token. Of course, if the next token is ), we must reduce; shifting is invalid because no single rule can reduce the token sequence - 2 ) or anything starting with that. But if the next token is * or **, we have a choice: either shifting or reduction would allow the parse to complete, but with different results.\nTo decide which one Ocamlyacc should do, we must consider the results. If the next operator token op is shifted, then it must be reduced first in order to permit another opportunity to reduce the difference. The result is (in effect) 1 - (2 op 3). On the other hand, if the subtraction is reduced before shifting op, the result is (1 - 2) op 3. Clearly, then, the choice of shift or reduce should depend on the relative precedence of the operators - and op: * should be shifted first, but not **.\nWhat about input such as 1 - 2 - 5; should this be (1 - 2) - 5 or should it be 1 - (2 - 5)? For most operators we prefer the former, which is called left association. The latter alternative, right association, is desirable for assignment operators. The choice of left or right association is a matter of whether the parser chooses to shift or reduce when the stack contains 1 - 2 and the look-ahead token is -: shifting makes right-associativity.\nSpecifying Operator Precedence Ocamlyacc allows you to specify these choices with the operator precedence declarations %left and %right. Each such declaration contains a list of tokens, which are operators whose precedence and associativity is being declared. The %left declaration makes all those operators left-associative and the %right declaration makes them right-associative. A third alternative is %nonassoc, which declares that it is a syntax error to find the same operator twice \u0026ldquo;in a row\u0026rdquo;.\nThe relative precedence of different operators is controlled by the order in which they are declared. The first %left or %right declaration in the file declares the operators whose precedence is lowest, the next such declaration declares the operators whose precedence is a little higher, and so on.\nPrecedence Examples In our example, we would want the following declarations:\n%left LT %left MINUS %left MULTIPLY  In a more complete example, which supports other operators as well, we would declare them in groups of equal precedence. For example, \u0026lsquo;+\u0026rsquo; is declared with \u0026lsquo;-\u0026rsquo;:\n%left LT GT EQ NE LE GE %left PLUS MINUS %left MULTIPLY DIVIDE  (Here NE and so on stand for the operators for \u0026ldquo;not equal\u0026rdquo; and so on. We assume that these tokens are more than one character long and therefore are represented by names, not character literals.)\nHow Precedence Works The first effect of the precedence declarations is to assign precedence levels to the terminal symbols declared. The second effect is to assign precedence levels to certain rules: each rule gets its precedence from the last terminal symbol mentioned in the components. (You can also specify explicitly the precedence of a rule. See Context-Dependent Precedence.)\nFinally, the resolution of conflicts works by comparing the precedence of the rule being considered with that of the look-ahead token. If the token\u0026rsquo;s precedence is higher, the choice is to shift. If the rule\u0026rsquo;s precedence is higher, the choice is to reduce. If they have equal precedence, the choice is made based on the associativity of that precedence level. The verbose output file made by -v (see Invoking Ocamlyacc) says how each conflict was resolved.\nNot all rules and not all tokens have precedence. If either the rule or the look-ahead token has no precedence, then the default is to shift.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/shiftreduceconflicts/",
	"title": "Shift Reduct Conflicts",
	"tags": [],
	"description": "The situation, where either a shift or a reduction would be valid, is called a shift/reduce conflict.",
	"content": "Suppose we are parsing a language which has if-then and if-then-else statements, with a pair of rules like this:\nif_stmt: IF expr THEN stmt | IF expr THEN stmt ELSE stmt ;  Here we assume that IF, THEN and ELSE are terminal symbols for specific keyword tokens.\nWhen the ELSE token is read and becomes the look-ahead token, the contents of the stack (assuming the input is valid) are just right for reduction by the first rule. But it is also legitimate to shift the ELSE, because that would lead to eventual reduction by the second rule.\nThis situation, where either a shift or a reduction would be valid, is called a shift/reduce conflict. Ocamlyacc is designed to resolve these conflicts by choosing to shift, unless otherwise directed by operator precedence declarations. To see the reason for this, let\u0026rsquo;s contrast it with the other alternative.\nSince the parser prefers to shift the ELSE, the result is to attach the else-clause to the innermost if-statement, making these two inputs equivalent:\nif x then if y then win (); else lose; if x then do; if y then win (); else lose; end;  But if the parser chose to reduce when possible rather than shift, the result would be to attach the else-clause to the outermost if-statement, making these two inputs equivalent:\nif x then if y then win (); else lose; if x then do; if y then win (); end; else lose;  The conflict exists because the grammar as written is ambiguous: either parsing of the simple nested if-statement is legitimate. The established convention is that these ambiguities are resolved by attaching the else-clause to the innermost if-statement; this is what Ocamlyacc accomplishes by choosing to shift rather than reduce. (It would ideally be cleaner to write an unambiguous grammar, but that is very hard to do in this case.) This particular ambiguity was first encountered in the specifications of Algol 60 and is called the \u0026ldquo;dangling else\u0026rdquo; ambiguity.\nThe definition of if_stmt above is solely to blame for the conflict, but the conflict does not actually appear without additional rules. Here is a complete Ocamlyacc input file that actually manifests the conflict:\n%token IF THEN ELSE variable %% stmt: expr | if_stmt ; if_stmt: IF expr THEN stmt | IF expr THEN stmt ELSE stmt ; expr: variable ;  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/symbols/",
	"title": "Symbols, Terminal and Nonterminal",
	"tags": [],
	"description": "Symbols in Ocamlyacc grammars represent the grammatical classifications of the language. A terminal symbol (also known as a token type) represents a class of syntactically equivalent tokens. A nonterminal symbol stands for a class of syntactically equivalent groupings.",
	"content": "Symbols in Ocamlyacc grammars represent the grammatical classifications of the language.\nA terminal symbol (also known as a token type) represents a class of syntactically equivalent tokens. You use the symbol in grammar rules to mean that a token in that class is allowed. The symbol is represented in the Ocamlyacc parser by a value of variant type, and the lexer function function returns a token type to indicate what kind of token has been read.\nA nonterminal symbol stands for a class of syntactically equivalent groupings. The symbol name is used in writing grammar rules. It should start with lower case.\nSymbol names can contain letters, digits (not at the beginning), underscores.\nThe terminal symbols in the grammar is a token type which is a value of variable type in Ocaml. So it should be start with upper case. Each such name must be defined with a Ocamlyacc declaration with %token. See Token Type Names.\nThe value returned by the lexer function is always one of the terminal symbols. Each token type becomes a Ocaml value of variant type in the parser file, so lexer function can return one.\nBecause the lexer function is defined in a separate file, you need to arrange for the token-type definitions to be available there. After invoking \u0026ldquo;ocamlyacc filename.mly\u0026rdquo;, the file filename.mli is generated which contains token-type definitions. It is used in lexer function.\nThe symbol error is a terminal symbol reserved for error recovery (see Error Recovery; you shouldn\u0026rsquo;t use it for any other purpose.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parserinterface/errorfunctions/",
	"title": "Error Functions",
	"tags": [],
	"description": "The Ocamlyacc parser detects a parse error or syntax error whenever it reads a token which cannot satisfy any syntax rule.",
	"content": "The Ocamlyacc parser detects a parse error or syntax error whenever it reads a token which cannot satisfy any syntax rule. An action in the grammar can also explicitly proclaim an error, using the raise Parsing.Parse_error.\nThe Ocamlyacc parser expects to report the error by calling an error reporting function named parse_error, which is optional. The default parse_error function does nothing and returns. It is called by the parser function whenever a syntax error is found, and it receives one argument. For a parse error, the string is normally \u0026ldquo;syntax error\u0026rdquo;.\nThe following definition suffices in simple programs:\nlet parse_error s = print_endline s  After parse_error returns to the parse function, the latter will attempt error recovery if you have written suitable error recovery grammar rules (see Error Recovery). If recovery is impossible, the parse function will raise Parsing.Parse_error exception.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/examples/",
	"title": "Examples",
	"tags": [],
	"description": "",
	"content": "Now we show and explain three sample programs written using Ocamlyacc: a reverse polish notation calculator, an algebraic (infix) notation calculator, and a multi-function calculator. These examples are simple, but Ocamlyacc grammars for real programming languages are written the same way\n Reverse Polish Notation Calculator  Reverse Polish Notation Calculator: rpcalc\n Infix Notation Calculator  Infix Notation Calculator: calc\n Simple Error Recovery  Simple Error Recovery\n Location Tracking Calculator  Location Tracking Calculator: ltcalc\n Multi-Function Calculator  Multi-Function Calculator: mfcalc\n "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/semanticvalues/",
	"title": "Semantic values",
	"tags": [],
	"description": "A formal grammar is a mathematical construct. To define the language for Ocamlyacc, you must write a file expressing the grammar in Ocamlyacc syntax.",
	"content": "A formal grammar selects tokens only by their classifications: for example, if a rule mentions the terminal symbol `integer constant\u0026rsquo;, it means that any integer constant is grammatically valid in that position. The precise value of the constant is irrelevant to how to parse the input: if x+4 is grammatical then x+1 or x+3989 is equally grammatical.\nBut the precise value is very important for what the input means once it is parsed. A compiler is useless if it fails to distinguish between 4, 1 and 3989 as constants in the program! Therefore, each token in a Ocamlyacc grammar has both a token type and a semantic value. See Defining Language Semantics, for details.\nThe token type is a terminal symbol defined in the grammar, such as INTEGER, IDENTIFIER or SEMICOLON. It tells everything you need to know to decide where the token may validly appear and how to group it with other tokens. The grammar rules know nothing about tokens except their types.\nThe semantic value has all the rest of the information about the meaning of the token, such as the value of an integer, or the name of an identifier. (A token such as SEMICOLON which is just punctuation doesn\u0026rsquo;t need to have any semantic value.)\nFor example, an input token might be classified as token type INTEGER and have the semantic value 4. Another input token might have the same token type INTEGER but value 3989. When a grammar rule says that INTEGER is allowed, either of these tokens is acceptable because each is an INTEGER. When the parser accepts the token, it keeps track of the token\u0026rsquo;s semantic value.\nEach grouping can also have a semantic value as well as its nonterminal symbol. For example, in a calculator, an expression typically has a semantic value that is a number. In a compiler for a programming language, an expression typically has a semantic value that is a tree structure describing the meaning of the expression.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/examples/simpleerrorrecovery/",
	"title": "Simple Error Recovery",
	"tags": [],
	"description": "Simple Error Recovery",
	"content": "Up to this point, this manual has not addressed the issue of error recovery\u0026mdash;how to continue parsing after the parser detects a syntax error. All we have handled is error reporting with parse_error. Recall that by default, the parser function raises exception after calling parse_error. This means that an erroneous input line causes the calculator program to raise exception and exit. Now we show how to rectify this deficiency.\nThe Ocamlyacc language itself includes the reserved word error, which may be included in the grammar rules. In the example below it has been added to one of the alternatives for line:\nline: NEWLINE | exp NEWLINE\t{ printf \u0026quot;\\t%.10g\\n\u0026quot; $1; flush stdout } | error NEWLINE\t{ } ;  This addition to the grammar allows for simple error recovery in the event of a parse error. If an expression that cannot be evaluated is read, the error will be recognized by the third rule for line, and parsing will continue. (The parse_error function is still called.) The action executes the statement and continues to parse.\nThis form of error recovery deals with syntax errors. There are other kinds of errors; for example, division by zero, which raises an exception that is normally fatal. A real calculator program must handle this exception and resume parsing input lines; it would also have to discard the rest of the current line of input. We won\u0026rsquo;t discuss this issue further because it is not specific to Ocamlyacc programs.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/syntaxofrules/",
	"title": "Syntax of grammar rules",
	"tags": [],
	"description": "A Ocamlyacc grammar rule has the following general form:",
	"content": "A Ocamlyacc grammar rule has the following general form:\nresult: symbol ... symbol { semantic-action } | ... | symbol ... symbol { semantic-action } ;  where result is the nonterminal symbol that this rule describes, and symbol are various terminal and nonterminal symbols that are put together by this rule (see Symbols).\nFor example,\nexp: exp PLUS exp\t{} ;  says that two groupings of type exp, with a PLUS token in between, can be combined into a larger grouping of type exp.\nWhitespace in rules is significant only to separate symbols. You can add extra whitespace as you wish.\nAt the end of the components there must be one action that determine the semantics of the rule. An action looks like this:\n{Ocaml code}  See Actions for detail description.\nMultiple rules for the same result can be written separately or can be joined with the vertical-bar character | as follows:\nresult: rule1-symbol ... rule1-symbol { rule1-semantic-action } | rule2-symbol ... rule2-symbol { rule2-semantic-action } | ... ;  They are still considered distinct rules even when joined in this way.\nIf components in a rule is empty, it means that result can match the empty string. For example, here is how to define a comma-separated sequence of zero or more exp groupings:\nexpseq: /* empty */\t{} | expseq1\t{} ; expseq1: exp\t{} | expseq1 COMMA exp\t{} ;  It is customary to write a comment /* empty */ in each rule with no components.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/lablgtk2-tutorial/",
	"title": "lablgtk2 tutorial",
	"tags": [],
	"description": "lablgtk2 tutorial",
	"content": ""
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/contextdependentprecedence/",
	"title": "Context-Dependent Precedence",
	"tags": [],
	"description": "Often the precedence of an operator depends on the context.",
	"content": "Often the precedence of an operator depends on the context. This sounds outlandish at first, but it is really very common. For example, a minus sign typically has a very high precedence as a unary operator, and a somewhat lower precedence (lower than multiplication) as a binary operator.\nThe Ocamlyacc precedence declarations, %left, %right and %nonassoc, can only be used once for a given token; so a token has only one precedence declared in this way. For context-dependent precedence, you need to use an additional mechanism: the %prec modifier for rules.\nThe %prec modifier declares the precedence of a particular rule by specifying a terminal symbol whose precedence should be used for that rule. It\u0026rsquo;s not necessary for that symbol to appear otherwise in the rule. The modifier\u0026rsquo;s syntax is:\n%prec terminal-symbol\nand it is written after the components of the rule. Its effect is to assign the rule the precedence of terminal-symbol, overriding the precedence that would be deduced for it in the ordinary way. The altered rule precedence then affects how conflicts involving that rule are resolved (see Operator Precedence).\nHere is how %prec solves the problem of unary minus. First, declare a precedence for a fictitious terminal symbol named UMINUS. There are no tokens of this type, but the symbol serves to stand for its precedence:\n... %left PLUS MINUS %left MULTIPLY %left UMINUS Now the precedence of UMINUS can be used in specific rules: exp: ... | exp MINUS exp ... | MINUS exp %prec UMINUS  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/",
	"title": "Grammar Files",
	"tags": [],
	"description": "",
	"content": "Ocamlyacc takes as input a context-free grammar specification and produces a Ocaml-language function that recognizes correct instances of the grammar. The Ocamlyacc grammar input file conventionally has a name ending in .yml. See Invoking Ocamlyacc.\n Grammar outline  A Ocamlyacc grammar file has four main sections, shown here with the appropriate delimiters:\n Symbols, Terminal and Nonterminal  Symbols in Ocamlyacc grammars represent the grammatical classifications of the language. A terminal symbol (also known as a token type) represents a class of syntactically equivalent tokens. A nonterminal symbol stands for a class of syntactically equivalent groupings.\n Syntax of grammar rules  A Ocamlyacc grammar rule has the following general form:\n Recursive Rules  A rule is called recursive when its result nonterminal appears also on its right hand side.\n Defineing Language Semantics  The grammar rules for a language determine only the syntax. The semantics are determined by the semantic values associated with various tokens and groupings, and by the actions taken when various groupings are recognized.\n Tracking Locations  Though grammar rules and semantic actions are enough to write a fully functional parser, it can be useful to process some additionnal informations, especially symbol locations.\n Nonterminal Symbols  The Ocamlyacc declarations section of a Ocamlyacc grammar defines the symbols used in formulating the grammar and the data types of semantic values. All token type must be declared. Nonterminal symbols must be declared if you need to specify which data type to use for the semantic value.\n Ocamlyacc Declarations  The Ocamlyacc declarations section of a Ocamlyacc grammar defines the symbols used in formulating the grammar and the data types of semantic values.\n "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/examples/locationtrackingcalculator/",
	"title": "Location Tracking Calculator",
	"tags": [],
	"description": "Location Tracking Calculator: ltcalc",
	"content": "This example extends the infix notation calculator with location tracking. This feature will be used to improve the error messages. For the sake of clarity, this example is a simple integer calculator, since most of the work needed to use locations will be done in the lexical analyser.\n3.4.1. Declarations for ltcalc\nThe Ocaml and Ocamlyacc declarations for the location tracking calculator are the same as the declarations for the infix notation calculator except open Lexing.\n/* file: ltcalc.mly / / Location tracking calculator. */ %{ open Printf open Lexing %}\n/* Ocamlyacc Declarations */ %token NEWLINE %token LPAREN RPAREN %token  NUM %token PLUS MINUS MULTIPLY DIVIDE CARET\n%left PLUS MINUS %left MULTIPLY DIVIDE %left NEG /* negation \u0026ndash; unary minus / %right CARET / exponentiation */\n%start input %type  input\n/* Grammar follows */ %%\nNote there are no declarations specific to locations. Defining a data type for storing locations is not needed: we will use the type provided by default (see Data Type of Locations), which is a four member structure with the following fields:\ntype Lexing.position = { pos_fname : string; pos_lnum : int; pos_bol : int; pos_cnum : int; } 3.4.2. Grammar Rules for ltcalc\nWhether handling locations or not has no effect on the syntax of your language. Therefore, grammar rules for this example will be very close to those of the previous example: we will only modify them to benefit from the new information.\nHere, we will use locations to report divisions by zero, and locate the wrong expressions or subexpressions.\ninput: /* empty */ { } | input line { } ; line: NEWLINE { } | exp NEWLINE { Printf.printf \u0026ldquo;\\t%.10g\\n\u0026rdquo; $1; flush stdout } ; exp: NUM { $1 } | exp PLUS exp { $1 +. $3 } | exp MINUS exp { $1 -. $3 } | exp MULTIPLY exp { $1 *. $3 } | exp DIVIDE exp { if $3 \u0026lt;\u0026gt; 0.0 then $1 /. $3 else ( let start_pos = Parsing.rhs_start_pos 3 in let end_pos = Parsing.rhs_end_pos 3 in printf \u0026ldquo;%d.%d-%d.%d: division by zero\u0026rdquo; start_pos.pos_lnum (start_pos.pos_cnum - start_pos.pos_bol) end_pos.pos_lnum (end_pos.pos_cnum - end_pos.pos_bol); 1.0 ) } | MINUS exp %prec NEG { -. $2 } | exp CARET exp { $1 ** $3 } | LPAREN exp RPAREN { $2 } ;\nThis code shows how to reach locations inside of semantic actions. For rule components, use the following functions,\nval Parsing.rhs_start_pos : int -\u0026gt; Lexing.position val Parsing.rhs_end_pos : int -\u0026gt; Lexing.position\nwhere the integer parameter says the position of the components on the right-hand side of the rule. It is 1 for the leftmost component.\nFor groupings, use the following functions.\nval Parsing.symbol_start_pos : unit -\u0026gt; Lexing.position val Parsing.symbol_end_pos : unit -\u0026gt; Lexing.position\nWe don\u0026rsquo;t need to calculate the values of the position: the output parser does it automatically. symbol_start_pos is set to the beginning of the leftmost component, and symbol_end_pos to the end of the rightmost component.\n3.4.3. The \u0026ldquo;ltcalc\u0026rdquo; Lexical Analyzer\nUntil now, we relied on Ocamlyacc\u0026rsquo;s defaults to enable location tracking. The next step is to rewrite the lexical analyser, and make it able to feed the parser with the token locations, as it already does for semantic values.\nTo this end, we must take into account every single character of the input text, to avoid the computed locations of being fuzzy or wrong. lexbuf.lex_curr_p.pos_cnum is updated automatically for scanning a character by the lexer engine, so you have to update only lexbuf.lex_curr_p.pos_lnum and lexbuf.lex_curr_p.pos_bol.\n(* file: lexer.mll ) ( Lexical analyzer returns one of the tokens: the token NUM of a floating point number, operators (PLUS, MINUS, MULTIPLY, DIVIDE, CARET, UMINUS), or NEWLINE. It skips all blanks and tabs, and unknown characters and raises End_of_file on EOF. *)\n{ open Ltcalc open Lexing let incr_lineno lexbuf = let pos = lexbuf.lex_curr_p in lexbuf.lex_curr_p \u0026lt;- { pos with pos_lnum = pos.pos_lnum + 1; pos_bol = pos.pos_cnum; } } let digit = [\u0026lsquo;0\u0026rsquo;-\u0026lsquo;9\u0026rsquo;] rule token = parse | [\u0026rsquo; \u0026lsquo; \u0026lsquo;\\t\u0026rsquo;] { token lexbuf } | \u0026lsquo;\\n\u0026rsquo; { incr_lineno lexbuf; NEWLINE } | digit+ | \u0026ldquo;.\u0026rdquo; digit+ | digit+ \u0026ldquo;.\u0026rdquo; digit* as num { NUM (float_of_string num) } | \u0026lsquo;+\u0026rsquo; { PLUS } | \u0026lsquo;-\u0026rsquo; { MINUS } | \u0026lsquo;*\u0026rsquo; { MULTIPLY } | \u0026lsquo;/\u0026rsquo; { DIVIDE } | \u0026lsquo;^\u0026rsquo; { CARET } | \u0026lsquo;(\u0026rsquo; { LPAREN } | \u0026lsquo;)\u0026rsquo; { RPAREN } | _ { token lexbuf } | eof { raise End_of_file }\nBasically, the lexical analyzer performs the same processing as before: it skips blanks and tabs, and reads numbers, operators or delimiters. In addition, it updates lexbuf.lex_curr_p containing the token\u0026rsquo;s location.\nNow, each time this function returns a token, the parser has its number as well as its semantic value, and its location in the text.\nRemember that computing locations is not a matter of syntax. Every character must be associated to a location update, whether it is in valid input, in comments, in literal strings, and so on.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/recursiverules/",
	"title": "Recursive Rules",
	"tags": [],
	"description": "A rule is called recursive when its result nonterminal appears also on its right hand side.",
	"content": "A rule is called recursive when its result nonterminal appears also on its right hand side. Nearly all Ocamlyacc grammars need to use recursion, because that is the only way to define a sequence of any number of a particular thing. Consider this recursive definition of a comma-separated sequence of one or more expressions:\nexpseq1: exp\t{} | expseq1 COMMA exp\t{} ;  Since the recursive use of expseq1 is the leftmost symbol in the right hand side, we call this left recursion. By contrast, here the same construct is defined using right recursion:\nexpseq1: exp\t{} | exp COMMA expseq1\t{} ;  Any kind of sequence can be defined using either left recursion or right recursion, but you should always use left recursion, because it can parse a sequence of any number of elements with bounded stack space. Right recursion uses up space on the Ocamlyacc stack in proportion to the number of elements in the sequence, because all the elements must be shifted onto the stack before the rule can be applied even once. See The Ocamyacc Parser Algorithm, for further explanation of this.\nIndirect or mutual recursion occurs when the result of the rule does not appear directly on its right hand side, but does appear in rules for other nonterminals which do appear on its right hand side.\nFor example:\nexpr: primary\t{} | primary PLUS primary\t{} ; primary: constant\t{} | LPAREN expr RPAREN\t{} ;  defines two mutually-recursive nonterminals, since each refers to the other.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/semanticactions/",
	"title": "Semantic actions",
	"tags": [],
	"description": "A grammar rule can have an action made up of Ocaml statements. Each time the parser recognizes a match for that rule, the action is executed.",
	"content": "In order to be useful, a program must do more than parse input; it must also produce some output based on the input. In a Ocamlyacc grammar, a grammar rule can have an action made up of Ocaml statements. Each time the parser recognizes a match for that rule, the action is executed. See Actions,\nMost of the time, the purpose of an action is to compute the semantic value of the whole construct from the semantic values of its parts. For example, suppose we have a rule which says an expression can be the sum of two expressions. When the parser recognizes such a sum, each of the subexpressions has a semantic value which describes how it was built up. The action for this rule should create a similar sort of value for the newly recognized larger expression.\nFor example, here is a rule that says an expression can be the sum of two subexpressions:\nexpr: expr PLUS expr { $1 + $3 } ;  The action says how to produce the semantic value of the sum expression from the values of the two subexpressions.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/lablgtk2-treeview-tutorial/",
	"title": "lablgtk2 treeview tutorial",
	"tags": [],
	"description": "lablgtk2 treeview tutorial",
	"content": ""
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/definesemantics/",
	"title": "Defineing Language Semantics",
	"tags": [],
	"description": "The grammar rules for a language determine only the syntax. The semantics are determined by the semantic values associated with various tokens and groupings, and by the actions taken when various groupings are recognized.",
	"content": " The grammar rules for a language determine only the syntax. The semantics are determined by the semantic values associated with various tokens and groupings, and by the actions taken when various groupings are recognized.\nFor example, the calculator calculates properly because the value associated with each expression is the proper number; it adds properly because the action for the grouping x + y is to add the numbers associated with x and y.\nData Types of Semantic Values In a simple program it may be sufficient to use the same data type for the semantic values of all language constructs. But in most programs, you will need different data types for different kinds of tokens and groupings. For example, a numeric constant may need type int or float, while a string constant or an identifier might need type string.\nTo use more than one data type for semantic values in one parser, Ocamlyacc requires you to do: Choose one of those types for each symbol (terminal or nonterminal) for which semantic values are used. This is done for tokens with the %token Ocamlyacc declaration (see Token Type Names) and for groupings with the %type Ocamlyacc declaration (see Nonterminal Symbols).\nActions An action accompanies a syntactic rule and contains Ocaml code to be executed each time an instance of that rule is recognized. The task of most actions is to compute a semantic value for the grouping built by the rule from the semantic values associated with tokens or smaller groupings.\nAn action consists of Ocaml statements surrounded by braces. All rules have just one action at the end of the rule, following all the components.\nThe Ocaml code in an action can refer to the semantic values of the components matched by the rule with the construct $n, which stands for the value of the nth component. The value of the evaluation of the action is the value for the grouping being constructed.\nHere is a typical example:\nexp: ... | exp PLUS exp { $1 +. $3 }  This rule constructs an exp from two smaller exp groupings connected by a plus-sign token. In the action, $1 and $3 refer to the semantic values of the two component exp groupings, which are the first and third symbols on the right hand side of the rule. The sum is returned so that it becomes the semantic value of the addition-expression just recognized by the rule. If there were a useful semantic value associated with the PLUS token, it could be referred to as \u0026lsquo;$2.\u0026rsquo;\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/locations/",
	"title": "Locations",
	"tags": [],
	"description": "Locations in order to keep track of the textual position, or location, of each syntactic construct.",
	"content": "Many applications, like interpreters or compilers, have to produce verbose and useful error messages. To achieve this, one must be able to keep track of the textual position, or location, of each syntactic construct. Ocamlyacc provides a mechanism for handling these locations.\nEach token has a semantic value. In a similar fashion, each token has an associated location, but the type of locations is the same for all tokens and groupings. Moreover, the output parser is equipped with a data structure for storing locations (see Locations, for more details).\nLike semantic values, locations can be reached in actions using functions of the Parsing module.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/examples/multifunctioncalculator/",
	"title": "Multi-Function Calculator",
	"tags": [],
	"description": "Multi-Function Calculator: mfcalc",
	"content": " Now that the basics of Ocamlyacc have been discussed, it is time to move on to a more advanced problem. The above calculators provided only five functions, +, -, *, / and ^. It would be nice to have a calculator that provides other mathematical functions such as sin, cos, etc.\nIn this example, we will show how to implement built-in functions whose syntax has this form:\nfunction_name (argument)  At the same time, we will add memory to the calculator, by allowing you to create named variables, store values in them, and use them later. Here is a sample session with the multi-function calculator:\n$ mfcalc pi = 3.14159265 3.1415927 sin(pi/2) 1 alpha = beta1 = 2.3 2.3 alpha 2.3 log(alpha) 0.83290912 exp(log(beta1)) 2.3 ^D $  Note that multiple assignment and nested function calls are permitted.\nDeclarations for mfcalc Here are the Ocaml and Ocamlyacc declarations for the multi-function calculator.\n/* file: mfcalc.mly */ %{ open Printf open Lexing let var_table = Hashtbl.create 16 %} /* Ocamlyacc Declarations */ %token NEWLINE %token LPAREN RPAREN EQ %token \u0026lt;float\u0026gt; NUM %token PLUS MINUS MULTIPLY DIVIDE CARET %token \u0026lt;string\u0026gt; VAR %token \u0026lt;float-\u0026gt;float\u0026gt; FNCT %left PLUS MINUS %left MULTIPLY DIVIDE %left NEG\t/* negation -- unary minus */ %right CARET\t/* exponentiation */ %start input %type \u0026lt;unit\u0026gt; input /* Grammar follows */ %%  Since values can have various types, it is necessary to associate a type with each grammar symbol whose semantic value is used. These symbols are NUM, VAR, FNCT, and exp. The declarations of terminals are augmented with information about their data type (placed between angle brackets).\nThe data type of non-terminal, exp, is nomally declared implicitly by the action.\nIn header section, a hash table called var_table is created for storing variable\u0026rsquo;s name and value. This will be used in the semantic action part. See The mfcalc Symbol Table.\nGrammar Rules for mfcalc Here are the grammar rules for the multi-function calculator. Most of them are copied directly from calc; three rules, those which mention VAR or FNCT, are new.\ninput:\t/* empty */\t{ } | input line\t{ } ; line:\tNEWLINE\t{ } | exp NEWLINE\t{ printf \u0026quot;\\t%.10g\\n\u0026quot; $1; flush stdout } | error NEWLINE\t{ } ; exp:\tNUM\t{ $1 } | VAR\t{ try Hashtbl.find var_table $1 with Not_found -\u0026gt; printf \u0026quot;no such variable '%s'\\n\u0026quot; $1; 0.0 } | VAR EQ exp\t{ Hashtbl.replace var_table $1 $3; $3 } | FNCT LPAREN exp RPAREN\t{ $1 $3 } | exp PLUS exp\t{ $1 +. $3 } | exp MINUS exp\t{ $1 -. $3 } | exp MULTIPLY exp\t{ $1 *. $3 } | exp DIVIDE exp\t{ $1 /. $3 } | MINUS exp %prec NEG\t{ -. $2 } | exp CARET exp\t{ $1 ** $3 } | LPAREN exp RPAREN\t{ $2 } ; %%  For the meaning of the semantic actions related with VAR, see The mfcalc Symbol Table.\nThe mfcalc Symbol Table The multi-function calculator requires a symbol table to keep track of the names and meanings of variables and functions. This doesn\u0026rsquo;t affect the grammar rules (except for the actions) or the Ocamlyacc declarations, but it requires some additional Ocaml functions for support.\nIn this example, we use two symbol tables: one for variables and one for functions. The variable symbol table is defined and used in parser and the function symbol table is defined and used in lexer.\nThe variable symbol table itself is implemented using the hash table. It has a key of string type and a value of float type.\nIt is a simple job to modify this code to install predefined variables such as pi or e as well.\nTwo important functions allow look-up and installation of symbols in the symbol table. The function Hashtbl.replace is passed a name and the value of the variable to be installed. The function Hashtbl.find is passed the name of the symbol to look up. If found, the value of that symbol is returned; otherwise zero is returned.\nThe lexical analyzer function must now recognize variables, numeric values, and the arithmetic operators. Strings of alphanumeric characters with a leading non-digit are recognized as either variables or functions depending on what the symbol table says about them.\nThe string is used for look up in the function symbol table. If the name appears in the table, the corresponding function is returned to the parser function as the value of FNCT. If it is not, VAR with the string is returned.\nNo change is needed in the handling of numeric values and arithmetic operators in the lexical analyzer function.\n(* file: lexer.mll *) { open Mfcalc open Lexing let create_hashtable size init = let tbl = Hashtbl.create size in List.iter (fun (key, data) -\u0026gt; Hashtbl.add tbl key data) init; tbl let fun_table = create_hashtable 16 [ (\u0026quot;sin\u0026quot;, sin); (\u0026quot;cos\u0026quot;, cos); (\u0026quot;tan\u0026quot;, tan); (\u0026quot;asin\u0026quot;, asin); (\u0026quot;acos\u0026quot;, acos); (\u0026quot;atan\u0026quot;, atan); (\u0026quot;log\u0026quot;, log); (\u0026quot;exp\u0026quot;, exp); (\u0026quot;sqrt\u0026quot;, sqrt); ] } let digit = ['0'-'9'] let ident = ['a'-'z' 'A'-'Z'] let ident_num = ['a'-'z' 'A'-'Z' '0'-'9'] rule token = parse | [' ' '\\t']\t{ token lexbuf } | '\\n'\t{ NEWLINE } | digit+ | \u0026quot;.\u0026quot; digit+ | digit+ \u0026quot;.\u0026quot; digit* as num { NUM (float_of_string num) } | '+'\t{ PLUS } | '-'\t{ MINUS } | '*'\t{ MULTIPLY } | '/'\t{ DIVIDE } | '^'\t{ CARET } | '('\t{ LPAREN } | ')'\t{ RPAREN } | '='\t{ EQ } | ident ident_num* as word { try let f = Hashtbl.find fun_table word in FNCT f with Not_found -\u0026gt; VAR word } | _\t{ token lexbuf } | eof\t{ raise End_of_file }  A hash table named fun_table is used for storing a function name and a value, that is, a function definition. It is initialized in the header part of the lexer file.\nThis program is both powerful and flexible. You may easily add new functions.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/parserstates/",
	"title": "Parser States",
	"tags": [],
	"description": "The function yyparse is implemented using a finite-state machine.",
	"content": "The function yyparse is implemented using a finite-state machine. The values pushed on the parser stack are not simply token type codes; they represent the entire sequence of terminal and nonterminal symbols at or near the top of the stack. The current state collects all the information about previous input which is relevant to deciding what to do next.\nEach time a look-ahead token is read, the current parser state together with the type of look-ahead token are looked up in a table. This table entry can say, \u0026ldquo;Shift the look-ahead token.\u0026rdquo; In this case, it also specifies the new parser state, which is pushed onto the top of the parser stack. Or it can say, \u0026ldquo;Reduce using rule number n.\u0026rdquo; This means that a certain number of tokens or groupings are taken off the top of the stack, and replaced by one grouping. In other words, that number of states are popped from the stack, and one new state is pushed.\nThere is one other alternative: the table can say that the look-ahead token is erroneous in the current state. This causes error processing to begin (see Error Recovery).\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parserinterface/",
	"title": "Parser interface",
	"tags": [],
	"description": "",
	"content": "The Ocamlyacc parser is actually Ocaml functions named after start symbols (see The Start-Symbol). Here we describe the interface conventions of parser functions and the other functions that it needs to use.\n Parser Functions  To cause parsing to occur, you call the parser function with two parameters.\n Lexical Functions  The lexical analyzer function, named after rule declarations, recognizes tokens from the input stream and returns them to the parser.\n Error Functions  The Ocamlyacc parser detects a parse error or syntax error whenever it reads a token which cannot satisfy any syntax rule.\n "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/ocamlyaccoutput/",
	"title": "Ocamlyacc output",
	"tags": [],
	"description": "When you run Ocamlyacc, you give it a Ocamlyacc grammar file as input. The output is a Ocaml source file that parses the language described by the grammar.",
	"content": "When you run Ocamlyacc, you give it a Ocamlyacc grammar file as input. The output is a Ocaml source file that parses the language described by the grammar. This file is called a Ocamlyacc parser. Keep in mind that the Ocamlyacc utility and the Ocamlyacc parser are two distinct programs: the Ocamlyacc utility is a program whose output is the Ocamlyacc parser that becomes part of your program.\nThe job of the Ocamlyacc parser is to group tokens into groupings according to the grammar rules\u0026mdash;for example, to build identifiers and operators into expressions. As it does this, it runs the actions for the grammar rules it uses.\nThe tokens come from a function called the lexical analyzer that you must supply in some fashion. The Ocamlyacc parser calls the lexical analyzer each time it wants a new token. It doesn\u0026rsquo;t know what is \u0026ldquo;inside\u0026rdquo; the tokens (though their semantic values may reflect this). Typically the lexical analyzer makes the tokens by parsing characters of text, but Ocamlyacc does not depend on this. See The Lexical Analyzer Function.\nThe Ocamlyacc parser file is Ocaml code which defines functions which implements that grammar. Entry functions of the generated Ocaml code are named after the start symbols in grammar file. These functions do not make a complete Ocaml program: you must supply some additional functions. One is the lexical analyzer which should be given as an argument of the parser entry function. Another is an error-reporting function which the parser calls to report an error. In addition, a complete Ocaml program must has to call one (or more) of the generated entry functions or the parser will never run. See Parser Interface.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/",
	"title": "Parser algorithm",
	"tags": [],
	"description": "As Ocamlyacc reads tokens, it pushes them onto a stack along with their semantic values.",
	"content": "As Ocamlyacc reads tokens, it pushes them onto a stack along with their semantic values. The stack is called the parser stack. Pushing a token is traditionally called shifting.\nFor example, suppose the infix calculator has read 1 + 5 *, with a 3 to come. The stack will have four elements, one for each token that was shifted.\nBut the stack does not always have an element for each token read. When the last n tokens and groupings shifted match the components of a grammar rule, they can be combined according to that rule. This is called reduction. Those tokens and groupings are replaced on the stack by a single grouping whose symbol is the result (left hand side) of that rule. Running the rule\u0026rsquo;s action is part of the process of reduction, because this is what computes the semantic value of the resulting grouping.\nFor example, if the infix calculator\u0026rsquo;s parser stack contains this:\n1 + 5 * 3  and the next input token is a newline character, then the last three elements can be reduced to 15 via the rule:\nexpr: expr MULTIPLY expr;  Then the stack contains just these three elements:\n1 + 15  At this point, another reduction can be made, resulting in the single value 16. Then the newline token can be shifted.\nThe parser tries, by shifts and reductions, to reduce the entire input down to a single grouping whose symbol is the grammar\u0026rsquo;s start-symbol (see Languages and Context-Free Grammars).\nThis kind of parser is known in the literature as a bottom-up parser.\n Lookahead Tokens  The Ocamlyacc parser does not always reduce immediately as soon as the last n tokens and groupings match a rule.\n Operator Precedence  the Ocamlyacc declarations for operator precedence allow you to specify when to shift and when to reduce.\n Shift Reduct Conflicts  The situation, where either a shift or a reduction would be valid, is called a shift/reduce conflict.\n Context-Dependent Precedence  Often the precedence of an operator depends on the context.\n Parser States  The function yyparse is implemented using a finite-state machine.\n Reduce/Reduce Conflicts  A reduce/reduce conflict occurs if there are two or more rules that apply to the same sequence of input.\n Misterious Reduce/Reduce Conflicts  Sometimes reduce/reduce conflicts can occur that don\u0026#39;t look warranted.\n "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/reducereduceconflicts/",
	"title": "Reduce/Reduce Conflicts",
	"tags": [],
	"description": "A reduce/reduce conflict occurs if there are two or more rules that apply to the same sequence of input.",
	"content": "A reduce/reduce conflict occurs if there are two or more rules that apply to the same sequence of input. This usually indicates a serious error in the grammar.\nFor example, here is an erroneous attempt to define a sequence of zero or more word groupings.\nsequence: /* empty */\t{ printf \u0026quot;empty sequence\\n\u0026quot; } | maybeword\t{} | sequence word\t{ printf \u0026quot;added word %s\\n\u0026quot; $2 } ; maybeword: /* empty */\t{ printf \u0026quot;empty maybeword\\n\u0026quot; } | word\t{ printf \u0026quot;single word %s\\n\u0026quot; $1 } ;  The error is an ambiguity: there is more than one way to parse a single word into a sequence. It could be reduced to a maybeword and then into a sequence via the second rule. Alternatively, nothing-at-all could be reduced into a sequence via the first rule, and this could be combined with the word using the third rule for sequence.\nThere is also more than one way to reduce nothing-at-all into a sequence. This can be done directly via the first rule, or indirectly via maybeword and then the second rule.\nYou might think that this is a distinction without a difference, because it does not change whether any particular input is valid or not. But it does affect which actions are run. One parsing order runs the second rule\u0026rsquo;s action; the other runs the first rule\u0026rsquo;s action and the third rule\u0026rsquo;s action. In this example, the output of the program changes.\nOcamlyacc resolves a reduce/reduce conflict by choosing to use the rule that appears first in the grammar, but it is very risky to rely on this. Every reduce/reduce conflict must be studied and usually eliminated. Here is the proper way to define sequence:\nsequence: /* empty */\t{ printf \u0026quot;empty sequence\\n\u0026quot; } | sequence word { printf \u0026quot;added word %s\\n\u0026quot; $2 } ;  Here is another common error that yields a reduce/reduce conflict:\nsequence: /* empty */ | sequence words | sequence redirects ; words: /* empty */ | words word ; redirects:/* empty */ | redirects redirect ;  The intention here is to define a sequence which can contain either word or redirect groupings. The individual definitions of sequence, words and redirects are error-free, but the three together make a subtle ambiguity: even an empty input can be parsed in infinitely many ways!\nConsider: nothing-at-all could be a words. Or it could be two words in a row, or three, or any number. It could equally well be a redirects, or two, or any number. Or it could be a words followed by three redirects and another words. And so on.\nHere are two ways to correct these rules. First, to make it a single level of sequence:\nsequence: /* empty */ | sequence word | sequence redirect ;  Second, to prevent either a words or a redirects from being empty:\nsequence: /* empty */ | sequence words | sequence redirects ; words: word | words word ; redirects:redirect | redirects redirect ;  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/trackinglocations/",
	"title": "Tracking Locations",
	"tags": [],
	"description": "Though grammar rules and semantic actions are enough to write a fully functional parser, it can be useful to process some additionnal informations, especially symbol locations.",
	"content": " Though grammar rules and semantic actions are enough to write a fully functional parser, it can be useful to process some additionnal informations, especially symbol locations.\nThe way locations are handled is defined by providing a data type, and actions to take when rules are matched.\nData Type of Locations The data type for locations has the following type:\ntype position = { pos_fname : string;\t(* file name *) pos_lnum : int;\t(* line number *) pos_bol : int;\t(* the offset of the beginning of the line *) pos_cnum : int;\t(* the offset of the position *) }  The value of pos_bol field is the number of characters between the beginning of the file and the beginning of the line while the value of pos_cnum field is the number of characters between the beginning of the file and the position.\nThe lexing engine manages only the pos_cnum field of lexbuf.lex_curr_p with the number of characters read from the start of lexbuf. So you are reponsible for the other fields to be accurate. Before using the location in the parser, you have to set Lexing.lexbuf.lex_curr_p correctly in lexer, using such a function like this:\nlet incr_linenum lexbuf = let pos = lexbuf.Lexing.lex_curr_p in lexbuf.Lexing.lex_curr_p \u0026lt;- { pos with Lexing.pos_lnum = pos.Lexing.pos_lnum + 1; Lexing.pos_bol = pos.Lexing.pos_cnum; } ;;  Actions and Locations Actions are not only useful for defining language semantics, but also for describing the behavior of the output parser with locations. The most obvious way for building locations of syntactic groupings is very similar to the way semantic values are computed. In a given rule, several constructs can be used to access the locations of the elements being matched. The location of the nth component of the right hand side can be obtained with:\nval Parsing.rhs_start : int -\u0026gt; int val Parsing.rhs_end : int -\u0026gt; int  Parsing.rhs_start n returns the offset of the first character of the nth item on the right-hand side of the rule, while Parsing.rhs_end n returns the offset after the last character of the item. are to be called in the action part of a grammar rule only. n is 1 for the leftmost item and the first character in a file is at offset 0.\nOr you can use the following functions:\nval Parsing.rhs_start_pos : int -\u0026gt; Lexing.position val Parsing.rhs_end_pos : int -\u0026gt; Lexing.position   (Since Ocaml 3.08) These functions return a position instead of an offset (see Data Type of Locations).\n The location of the left hand side grouping can be referred by\nval Parsing.symbol_start : unit -\u0026gt; int val Parsing.symbol_end : unit -\u0026gt; int  The _symbolstart () returns the offset of the first character of the left-hand side of the rule while _symbolend () returns the offset after the last character.\n(Since Ocaml 3.08) The following functions are same as symbol_start and symbol_end, except returning a position instead of an offset (see Data Type of Locations).\nval Parsing.symbol_start_pos : unit -\u0026gt; Lexing.position val Parsing.symbol_end_pos : unit -\u0026gt; Lexing.position  Here is a basic example using the default data type for locations:\nexp:\t... | exp DIVIDE exp { if $3 \u0026lt;\u0026gt; 0.0 then $1 /. $3 else ( let start_pos = Parsing.rhs_start_pos 3 in let end_pos = Parsing.rhs_end_pos 3 in printf \u0026quot;%d.%d-%d.%d: division by zero\u0026quot; start_pos.pos_lnum (start_pos.pos_cnum - start_pos.pos_bol) end_pos.pos_lnum (end_pos.pos_cnum - end_pos.pos_bol); 1.0 ) }  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/errorrecovery/",
	"title": "Error Recovery",
	"tags": [],
	"description": "",
	"content": "It is not usually acceptable to have a program terminate on a parse error. For example, a compiler should recover sufficiently to parse the rest of the input file and check it for errors; a calculator should accept another expression.\nIn a simple interactive command parser where each input is one line, it may be sufficient to have the caller catch the exception and ignore the rest of the input line when that happens (and then call parse function again). But this is inadequate for a compiler, because it forgets all the syntactic context leading up to the error. A syntax error deep within a function in the compiler input should not cause the compiler to treat the following line like the beginning of a source file.\nYou can define how to recover from a syntax error by writing rules to recognize the special token error. This is a terminal symbol that is reserved for error handling. The Ocamlyacc parser generates an error token whenever a syntax error happens; if you have provided a rule to recognize this token in the current context, the parse can continue.\nFor example:\nstmnts: /* empty string */ {} | stmnts NEWLINE {} | stmnts exp NEWLINE {} | stmnts error NEWLINE {}\nThe fourth rule in this example says that an error followed by a newline makes a valid addition to any stmnts.\nWhat happens if a syntax error occurs in the middle of an exp? The error recovery rule, interpreted strictly, applies to the precise sequence of a stmnts, an error and a newline. If an error occurs in the middle of an exp, there will probably be some additional tokens and subexpressions on the stack after the last stmnts, and there will be tokens to read before the next newline. So the rule is not applicable in the ordinary way.\nBut Ocamlyacc can force the situation to fit the rule, by discarding part of the semantic context and part of the input. First it discards states and objects from the stack until it gets back to a state in which the error token is acceptable. (This means that the subexpressions already parsed are discarded, back to the last complete stmnts.) At this point the error token can be shifted. Then, if the old look-ahead token is not acceptable to be shifted next, the parser reads tokens and discards them until it finds a token which is acceptable. In this example, Ocamlyacc reads and discards input until the next newline so that the fourth rule can apply.\nThe choice of error rules in the grammar is a choice of strategies for error recovery. A simple and useful strategy is simply to skip the rest of the current input line or current statement if an error is detected:\nstmnt: error SEMICOLON {} /* on error, skip until SEMICOLON is read */\nIt is also useful to recover to the matching close-delimiter of an opening-delimiter that has already been parsed. Otherwise the close-delimiter will probably appear to be unmatched, and generate another, spurious error message:\nprimary: LPAREN expr RPAREN {} | LPAREN error RPAREN {} \u0026hellip; ;\nError recovery strategies are necessarily guesses. When they guess wrong, one syntax error often leads to another. In the above example, the error recovery rule guesses that an error is due to bad input within one stmnt. Suppose that instead a spurious semicolon is inserted in the middle of a valid stmnt. After the error recovery rule recovers from the first error, another syntax error will be found straightaway, since the text following the spurious semicolon is also an invalid stmnt.\nTo prevent an outpouring of error messages, the parser will output no error message for another syntax error that happens shortly after the first; only after three consecutive input tokens have been successfully shifted will error messages resume.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/parseralgorithm/mysteriousreducereductconflicts/",
	"title": "Misterious Reduce/Reduce Conflicts",
	"tags": [],
	"description": "Sometimes reduce/reduce conflicts can occur that don&#39;t look warranted.",
	"content": "Sometimes reduce/reduce conflicts can occur that don\u0026rsquo;t look warranted. Here is an example:\n%token ID COMMA COLON %% def: param_spec return_spec COMMA ; param_spec: type | name_list COLON type ; return_spec: type | name COLON type ; type: ID ; name: ID ; name_list: name | name COMMA name_list ;  It would seem that this grammar can be parsed with only a single token of look-ahead: when a param_spec is being read, an ID is a name if a comma or colon follows, or a type if another ID follows. In other words, this grammar is LR(1).\nHowever, Ocamlyacc, like most parser generators, cannot actually handle all LR(1) grammars. In this grammar, two contexts, that after an ID at the beginning of a param_spec and likewise at the beginning of a return_spec, are similar enough that Ocamlyacc assumes they are the same. They appear similar because the same set of rules would be active\u0026mdash;the rule for reducing to a name and that for reducing to a type. Ocamlyacc is unable to determine at that stage of processing that the rules would require different look-ahead tokens in the two contexts, so it makes a single parser state for them both. Combining the two contexts causes a conflict later. In parser terminology, this occurrence means that the grammar is not LALR(1).\nIn general, it is better to fix deficiencies than to document them. But this particular deficiency is intrinsically hard to fix; parser generators that can handle LR(1) grammars are hard to write and tend to produce parsers that are very large. In practice, Ocamlyacc is more useful as it is now.\nWhen the problem arises, you can often fix it by identifying the two parser states that are being confused, and adding something to make them look distinct. In the above example, adding one rule to return_spec as follows makes the problem go away:\n%token BOGUS ... %% ... return_spec: type | name COMMA type /* This rule is never used. */ | ID BOGUS ;  This corrects the problem because it introduces the possibility of an additional active rule in the context after the ID at the beginning of return_spec. This rule is not active in the corresponding context in a param_spec, so the two contexts receive distinct parser states. As long as the token BOGUS is never generated by yylex, the added rule cannot alter the way actual input is parsed.\nIn this particular example, there is another way to solve the problem: rewrite the rule for return_spec to use ID directly instead of via name. This also causes the two confusing contexts to have different sets of active rules, because the one for return_spec activates the altered rule for return_spec rather than the one for name.\nparam_spec: type | name_list COMMA type ; return_spec: type | ID COMMA type ;  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/nonterminal/",
	"title": "Nonterminal Symbols",
	"tags": [],
	"description": "The Ocamlyacc declarations section of a Ocamlyacc grammar defines the symbols used in formulating the grammar and the data types of semantic values.  All token type must be declared. Nonterminal symbols must be declared if you need to specify which data type to use for the semantic value.",
	"content": " The Ocamlyacc declarations section of a Ocamlyacc grammar defines the symbols used in formulating the grammar and the data types of semantic values. See Symbols.\nAll token type must be declared. Nonterminal symbols must be declared if you need to specify which data type to use for the semantic value (see Data Types of Semantic Values).\nThe first rule in the file also specifies the start symbol, by default. If you want some other symbol to be the start symbol, you must declare it explicitly (see Languages and Context-Free Grammars).\nToken Type Names The basic way to declare a token type name (terminal symbol) is as follows:\n%token name ... name %token \u0026lt;type\u0026gt; name ... name  Ocamlyacc will convert this into a token type in the parser, so that the lexer function can use the name name to stand for this token type\u0026rsquo;s code.\nIn the event that the token has a value, you must augment the %token declaration to include the data type alternative delimited by angle-brackets (see Data Types of Semantic Values).\nFor example:\n%token \u0026lt;float\u0026gt; NUM\t/* define toke NUM and its type */  The type part is an arbitrary Caml type expression,\nOperator Precedence Use the %left, %right or %nonassoc declaration to specify token\u0026rsquo;s precedence and associativity, all at once. These are called precedence declarations. See Operator Precedence, for general information on operator precedence.\nThe syntax of a precedence declaration is\n%left symbols ...symbols %right symbols ...symbols %nonassoc symbols ...symbols  They specify the associativity and relative precedence for all the symbols:\nThe associativity of an operator op determines how repeated uses of the operator nest: whether x op y op z is parsed by grouping x with y first or by grouping y with z first. %left specifies left-associativity (grouping x with y first) and %right specifies right-associativity (grouping y with z first). %nonassoc specifies no associativity, which means that x op y op z is considered a syntax error.\nThe precedence of an operator determines how it nests with other operators. All the tokens declared in a single precedence declaration have equal precedence and nest together according to their associativity. When two tokens declared in different precedence declarations associate, the one declared later has the higher precedence and is grouped first.\nNonterminal Symbols You can declare the value type of each nonterminal symbol for which values are used. This is done with a %type declaration, like this:\n%type \u0026lt;type\u0026gt; nonterminal ... nonterminal  Here nonterminal is the name of a nonterminal symbol, and type is the name of the type that you want. You can give any number of start nonterminal symbols in the same %type declaration, if they have the same value type. Use spaces to separate the symbol names.\nThis is necessary for start symbols. For the type part, see Token Type Names.\nThe Start-Symbol You have to declare the start symbols using %start declaration as follows:\n%start symbol ... symbol  Each start symbol has a parsing function with the same name in the output file so you can use it as an entry point for the grammar. As noted eariler, type should be assinged to each start symbol using %type directive (see Nonterminal Symbols).\nOcamlyacc Declaration Summary Here is a summary of the declarations used to define a grammar:\n %token: Declare a terminal symbol (token type name) with no precedence or associativity specified (see Token Type Names). %right: Declare a terminal symbol (token type name) that is right-associative (see Operator Precedence). %left: Declare a terminal symbol (token type name) that is left-associative (see Operator Precedence). %nonassoc: Declare a terminal symbol (token type name) that is nonassociative (using it in a way that would be associative is a syntax error) (see Operator Precedence). %type: Declare the type of semantic values for a nonterminal symbol (see Nonterminal Symbols). %start: Specify the grammar\u0026rsquo;s start symbol (see The Start-Symbol).  "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/grammar/declarations/",
	"title": "Ocamlyacc Declarations",
	"tags": [],
	"description": "The Ocamlyacc declarations section of a Ocamlyacc grammar defines the symbols used in formulating the grammar and the data types of semantic values.",
	"content": "The Ocamlyacc declarations section of a Ocamlyacc grammar defines the symbols used in formulating the grammar and the data types of semantic values. See Symbols.\nAll token type must be declared. Nonterminal symbols must be declared if you need to specify which data type to use for the semantic value (see Data Types of Semantic Values).\nThe first rule in the file also specifies the start symbol, by default. If you want some other symbol to be the start symbol, you must declare it explicitly (see Languages and Context-Free Grammars).\n4.7.1. Token Type Names\nThe basic way to declare a token type name (terminal symbol) is as follows:\n%token name \u0026hellip; name %token  name \u0026hellip; name\nOcamlyacc will convert this into a token type in the parser, so that the lexer function can use the name name to stand for this token type\u0026rsquo;s code.\nIn the event that the token has a value, you must augment the %token declaration to include the data type alternative delimited by angle-brackets (see Data Types of Semantic Values).\nFor example:\n%token  NUM /* define toke NUM and its type */\nThe type part is an arbitrary Caml type expression,\n4.7.2. Operator Precedence\nUse the %left, %right or %nonassoc declaration to specify token\u0026rsquo;s precedence and associativity, all at once. These are called precedence declarations. See Operator Precedence, for general information on operator precedence.\nThe syntax of a precedence declaration is\n%left symbols \u0026hellip;symbols %right symbols \u0026hellip;symbols %nonassoc symbols \u0026hellip;symbols\nThey specify the associativity and relative precedence for all the symbols:\nThe associativity of an operator op determines how repeated uses of the operator nest: whether x op y op z is parsed by grouping x with y first or by grouping y with z first. %left specifies left-associativity (grouping x with y first) and %right specifies right-associativity (grouping y with z first). %nonassoc specifies no associativity, which means that x op y op z is considered a syntax error.\nThe precedence of an operator determines how it nests with other operators. All the tokens declared in a single precedence declaration have equal precedence and nest together according to their associativity. When two tokens declared in different precedence declarations associate, the one declared later has the higher precedence and is grouped first.\n4.7.3. Nonterminal Symbols\nYou can declare the value type of each nonterminal symbol for which values are used. This is done with a %type declaration, like this:\n%type  nonterminal \u0026hellip; nonterminal\nHere nonterminal is the name of a nonterminal symbol, and type is the name of the type that you want. You can give any number of start nonterminal symbols in the same %type declaration, if they have the same value type. Use spaces to separate the symbol names.\nThis is necessary for start symbols. For the type part, see Token Type Names.\n4.7.4. The Start-Symbol\nYou have to declare the start symbols using %start declaration as follows:\n%start symbol \u0026hellip; symbol\nEach start symbol has a parsing function with the same name in the output file so you can use it as an entry point for the grammar. As noted eariler, type should be assinged to each start symbol using %type directive (see Nonterminal Symbols).\n4.7.5. Ocamlyacc Declaration Summary\nHere is a summary of the declarations used to define a grammar:\n%token Declare a terminal symbol (token type name) with no precedence or associativity specified (see Token Type Names).\n%right Declare a terminal symbol (token type name) that is right-associative (see Operator Precedence).\n%left Declare a terminal symbol (token type name) that is left-associative (see Operator Precedence).\n%nonassoc Declare a terminal symbol (token type name) that is nonassociative (using it in a way that would be associative is a syntax error) (see Operator Precedence).\n%type Declare the type of semantic values for a nonterminal symbol (see Nonterminal Symbols).\n%start Specify the grammar\u0026rsquo;s start symbol (see The Start-Symbol).\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/stages/",
	"title": "Stages in use ocamlyacc",
	"tags": [],
	"description": "The actual language-design process using Ocamlyacc, from grammar specification to a working compiler or interpreter, has these parts:",
	"content": "The actual language-design process using Ocamlyacc, from grammar specification to a working compiler or interpreter, has these parts:\nFormally specify the grammar in a form recognized by Ocamlyacc (see Ocamlyacc Grammar Files). For each grammatical rule in the language, describe the action that is to be taken when an instance of that rule is recognized. The action is described by a sequence of Ocaml statements.\nWrite a lexical analyzer to process input and pass tokens to the parser. The lexical analyzer may be written by hand in Ocaml (see The Lexical Analyzer Function). It could also be produced using ocamllex, but the use of ocamllex is not discussed in this manual.\nWrite a controlling function that calls the Ocamlyacc-produced parser.\nWrite error-reporting routines.\nTo turn this source code as written into a runnable program, you must follow these steps:\nRun Ocamlyacc on the grammar to produce the parser.\nCompile the code output by Ocamlyacc, as well as any other source files.\nLink the object files to produce the finished product.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/debugging/",
	"title": "Debugging your parser",
	"tags": [],
	"description": "",
	"content": "To debug the parser generated by ocamlyacc:\nGenerate parsing infomation in the file grammar.output using -v option (like \u0026ldquo;ocamlyacc -v filneme.mly\u0026rdquo;): the information consists of the parsing table and a report on conflicts.\nSet p option of the OCAMLRUNPARAM environment variable: for example, execute \u0026ldquo;export OCAMLRUNPARAM=\u0026lsquo;p\u0026rsquo; \u0026rdquo; on bash shell.\nThe parser prints messages about its actions such as shifting a token, reducing a rule.\nYou can find rule numbers and state numbers mentioned in the messages at the file grammar.output.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/concepts/overalllayout/",
	"title": "Overall layout of grammar",
	"tags": [],
	"description": "The general form of a Ocamlyacc grammar file is as follows:",
	"content": "The input file for the Ocamlyacc utility is a Ocamlyacc grammar file. The general form of a Ocamlyacc grammar file is as follows:\n%{ Header (Ocaml code) %} Ocamlyacc declarations %% Grammar rules %% Trailer (Additional Ocaml code)\nThe %%, %{ and %} are punctuation that appears in every Ocamlyacc grammar file to separate the sections.\nThe header may define types, variables and functions used in the actions.\nThe Ocamlyacc declarations declare the names of the terminal and nonterminal symbols, and may also describe operator precedence and the data types of semantic values of various symbols.\nThe grammar rules define how to construct each nonterminal symbol from its parts.\nThe Trailer can contain any Ocaml code you want to use.\n"
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/invokingocamlyacc/",
	"title": "Invoking Ocamlyacc",
	"tags": [],
	"description": "",
	"content": "The usual way to invoke Bison is as follows:\nocamlyacc filename.mly  Here filename.mly is the grammar file name. The parser file\u0026rsquo;s name is made by replacing the .mly with .ml. Thus, the \u0026ldquo;ocamlyacc foo.mly\u0026rdquo; yields foo.ml.\n Options  Ocamlyacc options\n "
},
{
	"uri": "https://ohama.github.io/ocaml/ocamlyacc-tutorial/license/",
	"title": "License",
	"tags": [],
	"description": "",
	"content": "  Bison license  Bison License\n Copyright and permission  Copyright and Permission\n "
},
{
	"uri": "https://ohama.github.io/ocaml/readme/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ohama.github.io/ocaml/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ohama.github.io/ocaml/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]